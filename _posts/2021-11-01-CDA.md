---
toc: true
layout: post
description: 5장
categories: [statistics,python]
title: 추정
---

[kaggle/GREG HAMEL/Hypothesis Testing](https://www.kaggle.com/hamelg/python-for-data-24-hypothesis-testing)

---

# 05_CDA(Confirmatory Data Analysis)

- 어떤 현상이 '우연'인지 그렇지 않은지를 확인하기 위함


```python
import scipy.stats as spst
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import math
```

## Comparative Type Test

### One Sample T-Test
- 샘플 A의 평균이 x와 다른가? - p-value가 낮으면 '다르다!'
- 귀무가설 : 같다
- 대립가설 : 다르다


```python
print(spst.poisson.rvs.__doc__)
```


```python
np.random.seed(6)

population_ages1 = spst.poisson.rvs(loc=18, mu=35, size=150000) # loc: lowest x value, mu: middle of distribution
population_ages2 = spst.poisson.rvs(loc=18, mu=10, size=100000)
population_ages = np.concatenate((population_ages1, population_ages2))

minnesota_ages1 = spst.poisson.rvs(loc=18, mu=30, size=30)
minnesota_ages2 = spst.poisson.rvs(loc=18, mu=10, size=20)
minnesota_ages = np.concatenate((minnesota_ages1, minnesota_ages2))

print( population_ages.mean())
print( minnesota_ages.mean())
```

    43.000112
    39.26
    


```python
spst.ttest_1samp(a = minnesota_ages,               # Sample data
                 popmean = population_ages.mean())  # Pop mean
```




    Ttest_1sampResult(statistic=-2.5742714883655027, pvalue=0.013118685425061678)



**pvalue** : 0.013118685425061678
* 정직한 설명 : 귀무가설이 참이라는 전제하에 이렇게 데이터가 관찰될 확률이 0.0....01%정도라는 뜻이다.
* 발칙한 설명 : 기존 배너보다 나을 확률이 99%를 넘는다는 뜻이다.

**statistic** : 2.5742714883655027
* 신호/노이즈, 즉 신호가 노이즈보다 2.57배 높다는 뜻


```python
vals = spst.t.ppf([0.05, 0.95] # Quantile to check
                  , 49)# minnesota_ages' Degrees of freedom
print(vals)
```

    [-1.67655089  1.67655089]
    


```python
# print(spst.t.ppf.__doc__)
# print(spst.t.cdf.__doc__)
spst.t.cdf(vals, 49)
```




    array([0.05, 0.95])



1) For a lower-tailed test, p-value = cdf(test_statistic)
2) For an upper-tailed test, p-value = 1 - cdf(test_statistic)
3) For a two-tailed test, p-value = 2 * (1 - cdf(|test_statistic|))


```python
spst.t.cdf(x= -2.5742,      # T-test statistic
               df= 49) * 2   # two-tailed test
```




    0.013121066545690117



t-test의 p-value 0.013121066545690117과 같음



```python
sigma = minnesota_ages.std()/math.sqrt(50)  # Sample stdev/sample size

spst.t.interval(0.95,                        # Confidence level 95로 할 때 43 평균이 포함 안됨
                 df = 49,                     # Degrees of freedom
                 loc = minnesota_ages.mean(), # Sample mean
                 scale= sigma)                # Standard dev estimate
```




    (36.369669080722176, 42.15033091927782)




```python

spst.t.interval(0.99,                        # 99로 하면 43 평균이 포함됨
                 df = 49,                     
                 loc = minnesota_ages.mean(), 
                 scale= sigma)                
```




    (35.40547994092107, 43.11452005907893)



### Two Sample T-Test
- A와 B가 다른가? p-value가 낮으면 '다르다'!


```python
# 분산의 동일성 검정
spst.levene(A,B)
# pvalue가 통상적인 기준인 0.1보다 크므로 분산 동일하다는 가정 받아들임.
```




    LeveneResult(statistic=0.5208519677996435, pvalue=0.485536773334305)




```python
spst.ttest_ind(A, B, equal_var=True) # equal_var는 등분산 여부인데, 모르면 False
```




    Ttest_indResult(statistic=-2.476489813980959, pvalue=0.030764898866015765)



### Paired T-Test
- 한 집단에서 전-후 비교(Before-After) - 당연히 p-value 낮으면 다른 것


```python
pres_raw = {'before':[142,140,144,144,142,146,149,150,142,148],
            'after':[138,136,147,139,143,141,143,145,136,146] }
pres_df = pd.DataFrame(pres_raw)
print(pres_df)
```

       before  after
    0     142    138
    1     140    136
    2     144    147
    3     144    139
    4     142    143
    5     146    141
    6     149    143
    7     150    145
    8     142    136
    9     148    146
    


```python
plt.subplot(1,2,1)
pres_df['before'].plot(kind = 'box', ylim = (130,160))

plt.subplot(1,2,2)
pres_df['after'].plot(kind = 'box', ylim = (130,160))
```




    <AxesSubplot:>




    
![png](05_CDA_files/05_CDA_22_1.png)
    



```python
spst.ttest_rel(pres_df.before, pres_df.after) # 얘가 Paried t-test
```




    Ttest_relResult(statistic=3.413793103448276, pvalue=0.007703223347263766)




```python
pres_df.before.mean() - pres_df.after.mean()
```




    3.299999999999983



### ANOVA(Analysis of Variance)
**귀무가설 : A,B,C 다 똑같다**  
**대립가설 : A,B,C 중 '무언가 하나는' 다를 것이다.**

대립가설 조심, A, B, C 중 뭐가 다르고, 얼마나 다르고 등은 전혀 알 수 없다. 따로 계산해야 한다.

[ 분산분석  검정의 가정사항 (assumptions of ANOVA test) ]

  (1) 독립성: 각 샘플 데이터는 서로 독립이다.  
  (2) 정규성: 각 샘플 데이터는 정규분포를 따르는 모집단으로 부터 추출되었다.  
  (3) 등분산성: 그룹들의 모집단의 분산은 모두 동일하다.  
  


```python
cotton_raw = {'15p':[7,7,15,11,9],
            '20p':[12,17,12,18,18],
            '25p':[14,18,18,19,19] }
cotten_df = pd.DataFrame(cotton_raw)
print(cotten_df)
```

       15p  20p  25p
    0    7   12   14
    1    7   17   18
    2   15   12   18
    3   11   18   19
    4    9   18   19
    


```python
spst.f_oneway(cotten_df['15p'],cotten_df['20p'],cotten_df['25p']) # 얘가 ANOVA
```




    F_onewayResult(statistic=9.588932806324113, pvalue=0.0032509417785530578)



##### 정석적인 해석 : 귀무가설이 참일 때, 이러한 데이터가 관측될 확률은 1.85% 정도이다. (1.85%확률을 뚫고 이런 데이터가 관측될 수도 있다.)

발칙한 해석 : 뭔가 하나는 차이가 날 확률이 98%는 넘는다.

## Associative Type Test

### Correlation Coefficient
**귀무가설 : X와 Y는 상관이 없다.(상관계수 = 0)**  
**대립가설 : 상관계수가 0이 아니다.**
- X와 Y를 별도로 시각화 해 볼 것


```python

spst.pearsonr(A,B) # X와 Y의 상관계수와 p-value
```




    (-0.25769442830628364, 0.5769040911771965)



- 결과는 튜플로 나오는데

1. 튜플의 첫 번째 값 : 상관계수를 뜻한다. 두 데이터의 선형성의 정도를 나타낸다.
2. p-value는 상관계수가 우연에 의해 일어나진 않았는지 판단한다.
    * 귀무가설 : 상관 계수가 0이다.
    * 대립가설 : 상관 계수가 0이 아니다.

pvalue가 0.57로 0.05보다 크기 때문에 귀무가설 받아들임
피어슨상관계쑤는 -0.25이므로 약한 음의 상관관계가 있음

### 교차분석(Chisquare_test)

티셔츠 구매여부와 반바지 구매여부는 관계가.. 있을까?!  
**귀무가설 : 티셔츠 구매와 바지 구매는 별개이다.(독립이다)**  
**대립가설 : 티셔츠를 구매와 바지는 독립이 아니다.관련이 있다..**


```python
# 고객별 셔츠와 바지의 구매 여부 데이터
shirt_raw = {'shirts':[0,0,0,0,0,0,1,1,0,0,1,1,1,1,1,0,0,0,0,0,1],
            'pants':[0,0,1,0,0,0,1,0,1,1,1,1,1,1,1,0,0,0,1,0,1] }
shirt_df = pd.DataFrame(shirt_raw)
print(shirt_df.head(10))
```

       shirts  pants
    0       0      0
    1       0      0
    2       0      1
    3       0      0
    4       0      0
    5       0      0
    6       1      1
    7       1      0
    8       0      1
    9       0      1
    


```python
# 데이터의 Crosstable
contingency = pd.crosstab(shirt_df['shirts'], shirt_df['pants'])
contingency
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>pants</th>
      <th>0</th>
      <th>1</th>
    </tr>
    <tr>
      <th>shirts</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
</div>




```python
chiresult = spst.chi2_contingency(contingency) # 카이제곱 검정
```


```python
# 결과 : 튜플로 4개 값 출력됨
print("카이제곱통계량 : {}".format(chiresult[0]))
print("p-value : {:.20f}".format(chiresult[1]))
print("자유도 : {}".format(chiresult[2]))
print("기대 빈도 분할표: \n", chiresult[3] ) #귀무가설에 대한 기대빈도.
```

    카이제곱통계량 : 4.317941433566433
    p-value : 0.03771251880967476516
    자유도 : 1
    기대 빈도 분할표: 
     [[6.19047619 6.80952381]
     [3.80952381 4.19047619]]
    

- 유의수준 0.05 하에 p-value가 매우 낮으므로 두 집단간 차이가 있다(바지 구매는 셔츠 구매와 관련이 있다)
- pants 0과 pants 1 그룹을 비교했을 때 shirts 0, 1의 차이가 있다. pants가 0, 1, 2였다면 0, 1, 2에 따라 차이가 있다라고 해석할 수 있음
