---
toc: true
layout: post
description: 7장
categories: [statistics,python]
title: 비모수통계 (goodness-of-fit, gomogeneity, independence)
---

[KOCW 통계학개론](http://www.kocw.or.kr/home/search/kemView.do?kemId=1215315)
[python 예시](https://www.statology.org/)

---

# 07_비모수통계

# 특징

## 모수통계 vs 비모수통계

### 모수통계
모집단의 분포에 관해 특별한 가정을 세운 다음 통계적 추론을 시도하는 것을 말함  
1) 추론의 대상이 모평균, 모비율, 모분산 등과 같은 모집단의 특성치, 즉 모수(parameter)라는 점  
2) 추론방법이 비교적 엄격한 가정을 전제로 하고 있다는 점  

### 비모수통계
1) 검정하고자 하는 가설이 모수와 관련된 것이 아닌 경우로서 적합도 검정이나 독립성 또는 동일성 검정, 표본의 무작위성 검정 등이 여기에 속함  
2) 모집단의 분포가 명확하지 않아서 모수 통계방법을 사용하기 곤란할 때로서 모수통계의 대안으로 가정을 전제로 하지 않는 비모수 통계방법을 이용  
3) 자료가 서열(rank)을 나타내는 순위자료이거나 순수한 범주적 자료일 경우   
4) 간편한 방법으로 짧은 시간 내에 검정결과를 알고자 하는 경우  



## 유형

### 적합도
1) RUN 검정: 표본 배열이 무작위로 구성되어 있는지 검정  
2) Kolmogorov-Smirnov 검정(one sample): 표본의 분포가 가정한 분포를 따르는지 검정  

### 동질성
1) Wilcoxon Signed-Rank Test(부호 순위 검정): 두 paired 표본의 부호와 서열로 분포를 비교 (paired t-test)  
2) Mann-Whitney U 검정: 두 독립표본이 같은 분포를 따르는지 비교 (independent t-test)  
3) Kruskal-Wallis H 검정: 2 집단 이상의 독립표본 집단의 분포 비교 (one-way Anova)  
4) Friedman 검정: 3 집단 이상의 paired 표본 집단의 분포 비교 (two-way Anova)  

### 상관성
1) spearman 서열상관 계수: 서열 또는 비율 척도 자료로 평가대상간의 일치성 검정  
2) Kendall 서열상관 계수: 서열 또는 비율 척도 자료로 평가대상간의 일치성 검정  


<!-- # 사회연결망 분석(SNA) -->

## 적합도 goodness-of-fit

### RUN 검정
표본 배열이 무작위로 구성되어 있는지 검정   
hypothesis: H0 (null) is that The data was produced in a random manner   
syntax: runstest_1samp(x, cutoff='mean' or 'median', correction=True)   
result: z-test statistic, p-value  


```python
from statsmodels.sandbox.stats.runs import runstest_1samp 

#create dataset
data = [12, 16, 16, 15, 14, 18, 19, 21, 13, 13]

#Perform Runs test
runstest_1samp(data, correction=False)

# p값 0.50233이므로 0.05보다 크므로 귀무가설 수용, z-test statistic: -0.67082임 
```




    (-0.6708203932499369, 0.5023349543605021)



### Kolmogorov-Smirnov 검정
표본의 분포가 가정한 분포를 따르는지 검정   
hypothesis: H0 (null) is that The data come from a normal distribution    
syntax: one sample은 scipy.stats.kstest(), two sample은 scipy.stats.ks_2samp()  
result: statistic, pvalue  


```python
from numpy.random import seed
from numpy.random import poisson

seed(0)

#generate dataset of 100 values that follow a Poisson distribution with mean=5
data = poisson(5, 100)

from scipy.stats import kstest

#perform Kolmogorov-Smirnov test
kstest(data, 'norm')

# 포아송 분포로 추출했고 p값 1.0908062873170218e-103이므로 귀무가설 기각

```




    KstestResult(statistic=0.9072498680518208, pvalue=1.0908062873170218e-103)




```python
from numpy.random import randn
from numpy.random import lognormal

#generate two datasets
data1 = randn(100)
data2 = lognormal(3, 1, 100)

from scipy.stats import ks_2samp

#perform Kolmogorov-Smirnov test
ks_2samp(data1, data2)

# standard normal이랑 lognormal로 추출했고, pvalue 4.417521386399011e-57이므로 귀무가설 기각
```




    KstestResult(statistic=0.98, pvalue=4.395433779467016e-55)



## 동질성 homogeneity

### Wilcoxon Signed-Rank Test  
두 paired 표본의 부호와 서열로 분포를 비교 (paired t-test)   
두 paired 표본의 차이를 나타내는 분포가 정규분포를 따르지 않을 때, 모평균의 차이가 있는지  
hypothesis: H0 (null) is that there is a no difference in the data between the two groups  
                        혹은  the mean data is equal between the two group  
syntax: wilcoxon(x, y, alternative='two-sided', 'less' or 'greater')  
result: t statistic, pvalue  


```python
# mpg by new fuel treatment
group1 = [20, 23, 21, 25, 18, 17, 18, 24, 20, 24, 23, 19]
group2 = [24, 25, 21, 22, 23, 18, 17, 28, 24, 27, 21, 23]

import scipy.stats as stats

#perform the Wilcoxon-Signed Rank Test
stats.wilcoxon(group1, group2)

# 양측검정으로 p값이 0.044이므로 mpg가 같다는 귀무가설 기각
```

    C:\Users\Administrator\anaconda3\lib\site-packages\scipy\stats\morestats.py:2967: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.
      warnings.warn("Exact p-value calculation does not work if there are "
    




    WilcoxonResult(statistic=10.5, pvalue=0.044065400736826854)



### Mann-Whitney U 검정
두 독립표본이 같은 분포를 따르는지 비교 (independent t-test)  
sample 크기가 30보다 작고, 표본분포가 정규분포를 따르지 않을 때, 두 독립표본의 차이가 있는지
hypothesis: H0 (null) is that there is a no difference in the data between the two groups   
syntax: mannwhitneyu(x, y, alternative='two-sided', 'less' or 'greater')  
result: t statistic, pvalue  


```python
# mpg by new fuel treatment
group1 = [20, 23, 21, 25, 18, 17, 18, 24, 20, 24, 23, 19]
group2 = [24, 25, 21, 22, 23, 18, 17, 28, 24, 27, 21, 23]

import scipy.stats as stats

#perform the Mann-Whitney U test
stats.mannwhitneyu(group1, group2, alternative='two-sided')

# 양측검정으로 p값이 0.21138945901258455이므로 mpg가 같다는 귀무가설 기각
```




    MannwhitneyuResult(statistic=50.0, pvalue=0.21138945901258455)



### Kruskal-Wallis H 검정
2 집단 이상의 독립표본 집단의 분포 비교 (one-way Anova)  
세 독립표본의 평균간에 차이가 있는지  
hypothesis: H0 (null) is that the median is equal across all groups  
syntax: stats.kruskal(a,b,c)
result: statistic, pvalue   


```python
# plant measurement
group1 = [7, 14, 14, 13, 12, 9, 6, 14, 12, 8]
group2 = [15, 17, 13, 15, 15, 13, 9, 12, 10, 8]
group3 = [6, 8, 8, 9, 5, 14, 13, 8, 10, 9]

from scipy import stats

#perform Kruskal-Wallis Test 
stats.kruskal(group1, group2, group3)

# p값이 0.043114289703508814이므로 세 plant growth의 중앙값은 다르다
```




    KruskalResult(statistic=6.287801578353988, pvalue=0.043114289703508814)




### Friedman 검정
3 집단 이상의 paired 표본 집단의 분포 비교 (two-way Anova)  
3 집단 이상의 평균이 통계적으로 유의미한 차이가 있는지  
hypothesis: The mean for each population is equal
syntax: stats.friedmanchisquare(a), b, c)
result: statistic, pvalue   


```python
# response times for patient on each of the three drugs
group1 = [4, 6, 3, 4, 3, 2, 2, 7, 6, 5]
group2 = [5, 6, 8, 7, 7, 8, 4, 6, 4, 5]
group3 = [2, 4, 4, 3, 2, 2, 1, 4, 3, 2]

from scipy import stats

#perform Friedman Test
stats.friedmanchisquare(group1, group2, group3)

# p값이 0.0012612201221243594이므로 평균 반응시간이 다른다
```




    FriedmanchisquareResult(statistic=13.351351351351344, pvalue=0.0012612201221243594)



## 상관성 (독립성) independence

서열 또는 비율 척도 자료로 평가대상간의 일치성 검정  
ex) 값이 1,2,3,9999 여도 어차피 1,2,3,4 순위로 판단   

### Spearman Rank Correlation 서열상관 계수
hypothesis: H0 (null) is that correlation coefficient is 0.
syntax: 
result: rho
    -1: a perfect negative relationship between two variables  
    0: no relationship between two variables  
    1: a perfect positive relationship between two variables  
, p-value


```python
# math, science exam score of 10 students
import pandas as pd

#create DataFrame
df = pd.DataFrame({'student': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],
                   'math': [70, 78, 90, 87, 84, 86, 91, 74, 83, 85],
                   'science': [90, 94, 79, 86, 84, 83, 88, 92, 76, 75]})

from scipy.stats import spearmanr

#calculate Spearman Rank correlation and corresponding p-value
rho, p = spearmanr(df['math'], df['science'])

#print Spearman rank correlation and p-value
print(rho)

# -0.41818181818181815이므로 음의 상관관계 존재

print(p)

# p값이 0.22911284098281892이므로 그렇게 significant 하진 않음
```

    -0.41818181818181815
    0.22911284098281892
    

### kendall 서열상관 계수
[kendall_서열상관계수](https://www.geeksforgeeks.org/python-kendall-rank-correlation-coefficient/)
[kendall_추가예제](https://medium.com/@leejukyung/켄달타우-kendalltau-18fb90ba4e7)
spear만과 비교해서 표본이 적고, 동점이 많을 때에는 켄달 타우 계수 사용  

x1 > x2 and y1 > y2 or x1 < x2 and y1 < y2 -> 일치
x1 > x2 and y1 < y2 or x1 < x2 and y1 > y2 -> 불일치
일치 

hypothesis: H0 (null) is that correlation coefficient is 0.
syntax: kendalltau(x, y)
result: corr, p-value


```python
from scipy.stats import kendalltau
  
# 권위주의적성격(X)과 지위추구성향(Y)
X = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] # [x1, x2, x3, ...]
Y = [1, 3, 6, 2, 7, 4, 5, 10, 11, 8, 9, 12] # [y1, y2, y3, ...]


# Calculating Kendall Rank correlation
corr, _ = kendalltau(X, Y)
print('Kendall Rank correlation: %.5f' % corr)

# 0.0.69697이므로 X와 Y의 순위 상관은 비교적 높다고 판단

```

    Kendall Rank correlation: 0.69697
    


