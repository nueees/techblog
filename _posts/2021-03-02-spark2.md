---
toc: true
layout: post
description: section4
categories: [spark]
title: Spark ML
---
 
ğŸ“ [Spark User Guide](https://spark.apache.org/docs/latest/api/python/index.html), Spark The Definitive Guide

---


# 4. MLlib 

## 4.1. MLlib

### spark MLlib vs ScikitLearn

- spark DF ê¸°ë°˜ìœ¼ë¡œ ML êµ¬ë™
- feature vectorization: ì—¬ëŸ¬ê°œ columnsì„ í•˜ë‚˜ë¡œ
- estimatorê°€ fitì„ í˜¸ì¶œí•  ë•Œ model ê°ì²´ë¥¼ ë°˜í™˜í•˜ê³  ì—¬ê¸°ì„œ ì˜ˆì¸¡ ìˆ˜í–‰
- pipeline ì‚¬ìš© ê¶Œì¥


## 4.2. MLlib êµ¬ì„±ìš”ì†Œ


### Transformer
: StringIndexer, OneHotEncoder, VectorAssebler, StandardScaler, Tokenizer  

- ì›ë¡ ì ìœ¼ë¡œëŠ” í•˜ë‚˜ì˜ DataFrameì„ ë‹¤ë¥¸ DataFrameìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì„ ê°€ì§„ í´ë˜ìŠ¤ë“¤ì„ ì´ì¹­  
- TransformerëŠ” transform() ë©”ì†Œë“œë¡œ ë³€í™˜ ìˆ˜í–‰. transform()ì˜ ì…ë ¥ ì¸ìë¡œ DataFrameì„ ì…ë ¥í•˜ê³  ë³€í™˜ëœ DataFrameì„ ë°˜í™˜  


- ë³´í†µ ë ˆì´ë¸”/ì›-í•« ì¸ì½”ë”©ì„ í•˜ëŠ” ì¸ì½”ë”, ìŠ¤ì¼€ì¼ë§ ë³€í™˜ì„ í•˜ëŠ” ìŠ¤ì¼€ì¼ëŸ¬, Feature Vectorization ë“±ì˜ ì‘ì—… ìˆ˜í–‰  


- íŠ¹ì´í•˜ê²Œë„, Estimatorê°€ fit() í•˜ì—¬ ìƒì„±ëœ ML ëª¨ë¸ë„ Transformer ì—­í• ì„ ìˆ˜í–‰. ì¦‰ ëª¨ë¸ì´ ì˜ˆì¸¡í•˜ë ¤ë©´ transform() ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•˜ëŠ”ë° ì—¬ê¸°ì— ì…ë ¥ ì¸ìë¡œ DataFrameì´ í•„ìš”í•˜ë©°, ë°˜í™˜ëœ DataFrameì— ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ê°€ì§€ê³  ìˆìŒ  


### Estimator
: Classification, Regression, Clustering, Collaborative Filtering  


```
from pyspark.ml.classification import DecisionTreeClassifier

dt_estimator = DecisionTreeClassifier(featuresCol='features', labelCol='Survived')
dt_model = dt_estimator.fit(train_sdf) # train ë°ì´í„°ë¡œ í•™ìŠµ í›„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ 
predictions = dt_model.transform(test_sdf) # test ë°ì´í„°ë¡œ ì í•© í›„ í•´ë‹¹ ê²°ê³¼ë¡œ ì •í™•ë„ í‰ê°€

```

### Evaluator
: RegressionEvaluator, BinaryClassificationEvaluator, MultiClassificationEvaluator  
- BinaryClassificationEvaluatorëŠ” roc-auc ì§€í‘œë§Œ ì œê³µ  
- ì •í™•ë„(accuracy)ë¥¼ ì–»ê¸° ìœ„í•´ì„œëŠ” ì´ì§„ ë¶„ë¥˜ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ MulticlassClassificationEvaluator í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨  
- precision, recall, f1-scoreë¥¼ ì–»ê¸° ìœ„í•´ì„œëŠ” ì´ì§„ ë¶„ë¥˜ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ MulticlassClassificationEvaluator í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨  
- MulticlassClassificationEvaluatorë¡œ ì–»ì–´ì§€ëŠ” precision, recallì€ positive/negative ì˜ˆì¸¡ ë°ì´í„° ê±´ìˆ˜ë¥¼ ë°˜ì˜í•œ weighted precision, weighted recall ê°’ì„  
- í¸ë¦¬í•¨ì„ ìœ„í•´ì„œë¼ë©´ ì˜ˆì¸¡ ê²°ê³¼ Spark DataFrameì„ pandas DataFrameìœ¼ë¡œ ë³€ê²½í•˜ê³  ì‚¬ì´í‚·ëŸ° í‰ê°€ APIë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë”
ë‚˜ì€ ì„ íƒì¼ ìˆ˜ ìˆìŒ  

```
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

accuracy_evaluator = MulticlassClassificationEvaluator(labelCol='Survived', predictionCol='prediction', metricName='accuracy')
print(accuracy_evaluator.evaluate(predictions)) # ìœ„ Estimatorë¡œ ì¶”ì¶œí•œ ê²°ê³¼ predictions ë„£ì–´ì„œ ì •í™•ë„ í™•ì¸
```

### Pipeline
- ì—¬ëŸ¬ê°œì˜ ê°œë³„ì ì¸ Transformerì˜ ë³€í™˜ ì‘ì—…, Estimatorì˜ í•™ìŠµ ì‘ì—…ì„ ì¼ë ¨ì˜ Stage ì—°ê²°ì„ í†µí•´ ê°„ë‹¨í•œ API ì²˜ë¦¬ë¡œ êµ¬í˜„í•  ìˆ˜
ìˆê²Œ ë§Œë“¤ì–´ ì¤Œ  
- Pipelineì€ ê°œë³„ ë³€í™˜ ë° í•™ìŠµ ì‘ì—…ì„ Stageë¡œ ê°ê° ì •ì˜í•˜ì—¬ Pipelineì— ë“±ë¡í•œ ë’¤ Pipelineì˜ fit() ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ì—°ê²°ëœ
Stage ì‘ì—…ì„ ìˆ˜í–‰í•˜ì—¬ í•™ìŠµ ì§„í–‰, í•™ìŠµ ê²°ê³¼ë¡œ PipelineModelì´ ë°˜í™˜ë˜ë©° ì´ PipelineModelì—ì„œ ì˜ˆì¸¡ì„ ìœ„í•œ ë³€í™˜ ë° ì˜ˆì¸¡ ì‘
ì—…ì„ transform() ë©”ì†Œë“œë¡œ ìˆ˜í–‰  

```
from pyspark.ml.feature import StringIndexer, OneHotEncoder
from pyspark.ml import Pipeline

def encode_columns(sdf, input_cols=None, encode_gubun='label'):
    # label encodingê³¼ one hot encoding ë³€í™˜ ì»¬ëŸ¼ëª… ì§€ì •. 
    label_cols = ['label_'+col for col in input_cols]
    onehot_cols = ['onehot_'+col for col in input_cols]
    
    #pipelineì˜ stagesë¡œ ì§€ì •ëœ StringIndexerì™€ OneHotEncoder ê°ì²´ ìƒì„±. 
    label_encoder_stage = StringIndexer(inputCols=input_cols, outputCols=label_cols)
    onehot_encoder_stage = OneHotEncoder(inputCols=label_cols, outputCols=onehot_cols)
    
    # encode_gubunì´ labelì´ë©´ StringIndexer stageë§Œ ë“±ë¡, onehotì´ë©´ StringIndexer, OneHotEncoder ëª¨ë‘ ë“±ë¡. 
    stages = []
    if encode_gubun == 'label':
        stages = [label_encoder_stage]
    else:
        stages = [label_encoder_stage, onehot_encoder_stage]
        
    pipeline = Pipeline(stages=stages) # ìœ„ì—ì„œ ë§Œë“¤ì–´ì§„ ê°ì²´ë¡œ íŒŒì´í”„ë¼ì¸ ìƒì„±
    sdf = pipeline.fit(sdf).transform(sdf) # íŒŒì´í”„ë¼ì¸ í•™ìŠµ í›„ ì í•©
    
    return sdf
```

### Model Selection( and Tuning)
: randomSplit, TrainValidationSplit, CrossValidator, ParamGridBuilder  
- Spark MLì€ ì§ì ‘ì ìœ¼ë¡œ K-Fold ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì„ íƒí•˜ê²Œ ë§Œë“œëŠ” ì‚¬ì´í‚·ëŸ°ì˜ KFold í´ë˜ìŠ¤ë‚˜ êµì°¨ ê²€ì¦ ì„±ëŠ¥ ê²°ê³¼ë§Œ ë°˜í™˜í•´ì£¼
ëŠ” cross_val_score()ëŠ” ì§€ì›í•˜ì§€ ì•ŠìŒ (ì•„ë˜ sklearn ì˜ˆì œ)  

```
kfold = KFold(n_splits=5)
for train_index, test_index in kfold.split(iris_df):
X_train, X_test = iris_df.iloc[train_index], iris_df.iloc[test_index]
y_train, y_test = label_df.iloc[train_index], label_df.iloc[test_index]

scores = cross_val_score(dt_clf , data , label , scoring='accuracy',cv=3)
```

- Spark ML ì€ CrossValidator í´ë˜ìŠ¤ë¥¼ í†µí•´ì„œ êµì°¨ ê²€ì¦ ì§€ì› í•˜ì§€ë§Œ CrossValidatorëŠ” êµì°¨ ê²€ì¦ë§Œ ìˆ˜í–‰í•˜ì§€ ì•Šê³  í•˜ì´í¼ íŒŒë¼ë¯¸
í„° íŠœë‹ê¹Œì§€ ê°™ì´ ìˆ˜í–‰í•˜ë¯€ë¡œ ì‚¬ì´í‚·ëŸ°ì˜ GridSearchCVì™€ ìœ ì‚¬ (ì•„ë˜ sklearn ì˜ˆì œ)   

```
grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True, return_train_score=True)
grid_dtree.fit(X_train, y_train)
scores_df = pd.DataFrame(grid_dtree.cv_results_)
scores_df[['params', 'mean_test_score', 'rank_test_score', 
'split0_test_score', 'split1_test_score', 'split2_test_score']]
```

#### Spark ML ì‚¬ìš©  
```
cv = CrossValidator(estimator=dt, 
estimatorParamMaps=param_grid, evaluator=evaluator_accuracy, 
numFolds=3)

tvs = TrainValidationSplit(estimator=dt, 
estimatorParamMaps=param_grid, 
evaluator=evaluator_accuracy, trainRatio=0.75)

```

## 4.3. Feature Vectorization


### Label encoding: StringIndexer ì‚¬ìš©  

ë¬¸ìí˜• -> ìˆ«ìë¡œ ë³€ê²½  
ë³€í™˜ë  ì»¬ëŸ¼ëª…(category)ê³¼ ë³€í™˜ í›„ ì»¬ëŸ¼ëª…(category_index)ì„ ì…ë ¥  
```
from pyspark.ml.feature import StringIndexer

df
> +---+--------+
  | id|category|
  +---+--------+
  |  0|       a|
  |  1|       b|
  |  2|       c|
  |  3|       a|
  |  4|       a|
  |  5|       c|
  +---+--------+

indexer = StringIndexer(inputCol='category', outputCol='category_index')
# ì—¬ëŸ¬ ì»¬ëŸ¼ë„ ê°€ëŠ¥
# StringIndexer(inputCols=["category1", "category2"], outputCols=["label_encoded1", "label_encoded2"])

indexer_model = indexer.fit(df) # ë³€í™˜ë  dfë¥¼ ë„£ê³  í•™ìŠµì‹œí‚´
print(indexer_model) # ëª¨ë¸ì´ ë§Œë“¤ì–´ì§
> StringIndexerModel: uid=StringIndexer_0ec8942b1277, handleInvalid=error



indexed_df = indexer_model.transform(df) # ë§Œë“¤ì–´ì§„ ëª¨ë¸ì— dfë¥¼ ë„£ê³  transformí•˜ë©´ ë³€í™˜ í›„ dfê°€ ë°˜í™˜ ë¨
indexed_df.show()
> +---+--------+--------------+
  | id|category|category_index|
  +---+--------+--------------+
  |  0|       a|           0.0|
  |  1|       b|           2.0|
  |  2|       c|           1.0|
  |  3|       a|           0.0|
  |  4|       a|           0.0|
  |  5|       c|           1.0|
  +---+--------+--------------+

```

ìˆ«ìí˜• -> ë¬¸ìí˜•  
ì›ë³µ ì‹œí‚¤ê¸°  
```
from pyspark.ml.feature import IndexToString

converter = IndexToString(inputCol='category_index', outputCol='original_category')
converted = converter.transform(indexed_df)
converted.show()
> +---+--------+--------------+-----------------+
  | id|category|category_index|original_category|
  +---+--------+--------------+-----------------+
  |  0|       a|           0.0|                a|
  |  1|       b|           2.0|                b|
  |  2|       c|           1.0|                c|
  |  3|       a|           0.0|                a|
  |  4|       a|           0.0|                a|
  |  5|       c|           1.0|                c|
  +---+--------+--------------+-----------------+
```

### One-hot encoding: OneHotEncoder ì‚¬ìš©  

í¬ê¸°ë¥¼ ë²¡í„°ì˜ ì°¨ì›ìœ¼ë¡œ í•˜ê³ , í‘œí˜„í•˜ê³  ì‹¶ì€ ë‹¨ì–´ì˜ ì¸ë±ìŠ¤ì— 1ì˜ ê°’ì„ ë¶€ì—¬í•˜ê³ , ë‹¤ë¥¸ ì¸ë±ìŠ¤ì—ëŠ” 0ì„ ë¶€ì—¬í•˜ëŠ” ë²¡í„° í‘œí˜„ ë°©ì‹  
ex) 5ê°œì˜ ì¹´í…Œê³ ë¦¬(0, 1, 2, 3, 4)ê°€ ìˆì„ ê²½ìš°  
0ì€ [0.1, 0.0, 0.0, 0.0]  
1ì€ [0.0, 1.0, 0.0, 0.0]  
2ëŠ” [0.0, 0.0, 1.0, 0.0]  
3ì€ [0.0, 0.0, 0.0, 1.0]  
4ëŠ” [0.0, 0.0, 0.0, 0.0]  

OneHotEncoderë  ì»¬ëŸ¼ì€ ë°˜ë“œì‹œ **ìˆ«ìí˜•**ìœ¼ë¡œ ë³€í™˜ë˜ì–´ ìˆì–´ì•¼ í•¨
ë”°ë¼ì„œ OneHotEncoderë¥¼ String ì»¬ëŸ¼ì— ì ìš© ì‹œì—ëŠ” Label Encodingì„ ë¨¼ì € ì ìš© í›„ì— ë³€í™˜í•´ì•¼ í•¨  

dropLastëŠ” ë§ˆì§€ë§‰ ì¸ìë¥¼ ì œì™¸í• ì§€ë¥¼ ë‚˜íƒ€ëƒ„ (default=True)  
ìœ„ ì˜ˆì‹œì—ì„œ ë§ˆì§€ë§‰ ì¹´í…Œê³ ë¦¬ì¸ 4 [0.0, 0.0, 0.0, 0.0] ê°€ ì œì™¸ë¨  

OneHotEncoderëŠ” sparse vector í˜•íƒœë¡œ onehot encoding ì ìš©  

```
from pyspark.ml.feature import OneHotEncoder

df
> +---+--------------------------+
  | categoryIndex1|categoryIndex2|
  +---+--------------------------+
  |            0.0|           1.0|
  |            1.0|           0.0|
  |            2.0|           1.0|
  |            0.0|           2.0|
  |            0.0|           1.0|
  |            2.0|           0.0|
  +---+--------------------------+
  
encoder = OneHotEncoder(dropLast=True, inputCols=["categoryIndex1", "categoryIndex2"],
                        outputCols=["onehot_encoded1", "onehot_encoded2"])
encoded_model = encoder.fit(df) # ë³€í™˜ë  dfë¥¼ ë„£ê³  í•™ìŠµì‹œí‚´

encoded_df = encoded_model.transform(df) # ë§Œë“¤ì–´ì§„ ëª¨ë¸ì— dfë¥¼ ë„£ê³  transformí•˜ë©´ ë³€í™˜ í›„ dfê°€ ë°˜í™˜ ë¨
#encoded_df = encoded_model.fit(df).transform(df) # í•™ìŠµê³¼ ì í•© í•œêº¼ë²ˆì—ë„ ê°€ëŠ¥

print(encoded_df.show())
display(encoded_df)  
> +--------------+--------------+---------------+---------------+
  |categoryIndex1|categoryIndex2|onehot_encoded1|onehot_encoded2|
  +--------------+--------------+---------------+---------------+
  |           0.0|           1.0|  (3,[0],[1.0])|  (3,[1],[1.0])|
  |           1.0|           0.0|  (3,[1],[1.0])|  (3,[0],[1.0])|
  |           2.0|           1.0|  (3,[2],[1.0])|  (3,[1],[1.0])|
  |           0.0|           2.0|  (3,[0],[1.0])|  (3,[2],[1.0])|
  |           0.0|           1.0|  (3,[0],[1.0])|  (3,[1],[1.0])|
  |           2.0|           0.0|  (3,[2],[1.0])|  (3,[0],[1.0])|
  +--------------+--------------+---------------+---------------+

  
```

### ì—¬ëŸ¬ ì»¬ëŸ¼ í•œ ì»¬ëŸ¼ìœ¼ë¡œ encoding: VectorAssembler ì‚¬ìš©

ê¸°ì¡´ iris ì»¬ëŸ¼ë“¤ì„ featuresë¼ëŠ” í•˜ë‚˜ì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë³€ê²½  
```
df
> +--------------+--------------+---------------+---------------+
   'sepal_length'| 'sepal_width'| 'petal_length'| 'petal_width'
  +--------------+--------------+---------------+---------------+
    4.3          | 3.0          | 0.1           | 0.1
    4.4          | 2.9          | 1.4           | 0.2
    4.6          | 3.4          | 1.4           | 0.3
    4.6          | 3.6          | 1.0           | 0.2
 
iris_columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']
vec_assembler = VectorAssembler(inputCols=iris_columns, outputCol='features')
feature_vector_df = vec_assembler.transform(df) # vectorAssemblerëŠ” í•™ìŠµ(fit)ì—†ì´ ë°”ë¡œ transform í˜¸ì¶œ
> feature_vector_dfì˜ features ì»¬ëŸ¼
[4.3, 3.0, 0.1, 0.1]  
[4.4, 2.9, 1.4, 0.2]  
[4.6, 3.4, 1.4, 0.3]  
[4.6, 3.6, 1.0, 0.2] 

```






<br><br>
---

# 5. MLlib Classification


<br><br>
---

# 6. MLlib Regression


<br><br>
---

# 7. Use Case


<br><br>
---
