{
  
    
        "post0": {
            "title": "Data Lifecycle - Analyze & Visualize",
            "content": "Cloud Architecture Center . . . Process and analyze . 3.1. Processing large-scale data . source systems (Google Cloud Storage, Bigtable, Google Cloud SQL) 읽어온 큰 데이터를 처리하고 정규화하고 집계함. 데이터 양이 커서 클러스터로 분산 처리하거나 소프트웨어 툴들의 도움을 받음 . Dataproc . cluster에서 실행 (auto scaling) 기존 Hadoop, Hive, Spark 에플리캐이션과 연동 use case: Log processing, Reporting, On-demand Spark clusters, Machine learning . Dataflow . Serverless(cluster X), parallel 처리 (No-Ops) Spark나 Hadoop과 연동이 아닌 새로운 데이터 pipeline 처리 use case: MapReduce 안쓰는 parallel processing, User analytics, Data science, ETL, Log processing . Dataprep . UI-Driven Data Preparation (No-Ops, 필요시 scaling 가능) use case: Machine learning, Analytics . connect Dataprep to BigQuery . 1) Create Flow 2) Add dataset (import) 3) Select BigQuery (left pane) &amp; Create dataset 4) Import &amp; Add to Flow . inspect, process data . 1) Edit Recipe dataset의 sample을 Transformer view에서 확인 가능 (visualization) . execute job to load BigQuery . 1) click Run in Transformer page 2) click Edit on Create-CSV 3) select BigQuery then create table 4) name output table 5) click Update 6) click Run . job history에서 monitoring 가능 . . 3.2. Analyzing and querying data . BigQuery . 앞서 store 할 때 뿐만 아니라 분석할 때도 사용 use case: User analysis(adtech, clickstream, game telemetry), Device and operational metrics(IoT), BI . Machine learning . 처리된 결과를 확대시키거나 data-collection 최적화를 제공하기도 하고 결과 예측도 함 . 음성 인식 | 자연어 처리 | 번역 | 동영상 자동 분석 | AI 플랫폼 (TensorFlow) | . . Explore and visualize . . Cloud Architecture Center . . 4.1. Explore and visualize . Datalab . interactive한 web 기반 툴 pandas, numpy, scikit-learn 등의 다양한 toolkit 지원 . Data science ecosystem . Datalab 말고도, web 기반 툴인 Apache Zeppelin 지원 R 사용하면 Rstudio Server나 Microsoft ML Server 지원 Scala나 Java 사용하면 Jupyter 지원 . 4.2. Visualizing business intelligence results . Looker . BI platform . BI Engine . analysis service 관리 . Sheets . Spreadsheet visualization . Data Catalog . Data discovery and metadata management . Data Studio . Dashboarding and visualization . .",
            "url": "https://nueees.github.io/techblog/gcp/datastudio/2021/10/03/data-lifecycle-analyze-visualize.html",
            "relUrl": "/gcp/datastudio/2021/10/03/data-lifecycle-analyze-visualize.html",
            "date": " • Oct 3, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Data Lifecycle - Store",
            "content": "Cloud Architecture Center . . . 2.1. Storing object data . bulk로 넣는 File 형식일 때 . Google Cloud Storage . 타 cloud storages이 제공하는 대부분의 특성을 가짐 . 1) Off-site management 2) Quick implementation 3) Cost-effective 4) Scalability 5) Business continuity . . 2.2. Storing database data . RDBMS와 NoSQL같은 DB 저장 시 . Relational (RDBMS) . Google Cloud SQL (MySQL, PostgreSQL) | Spanner (Horizontally scalable) | 기존 ecosystem (Microsoft SQL Server) | . Non-relational (NoSQL) . Google Bigtable(wide-column) | Firestore (Flexible, scalable) | 기존 ecosystem (MongoDB, Cassandra) | . . 2.3. Storing data warehouse data . 분석용도로 DW에 큰 data 저장 시 . BigQuery . managed DW . Feature . a fully-managed, serverless data warehouse that enables scalable analysis over petabytes of data. . serverless cloud 서비스로 설치/운영이 필요없음 (NoOps) | RDBMS의 SQL 사용 (ANSI) | speed (in-memory BI Engine and machine learning built in) | handling big data supported by cloud scale infra | save 3 replication (data loss risk X) | batch / streaming . | easier than Hadoop, Spark: install, configure env, develop MapReduce logic… | . prerequisite: create Google Cloud project enable the BigQuery API create a service account (key) permissions to open the BigQuery Geo Viz permissions to open the Bucket1 . Interface . 1) Web UI . Query를 WEB UI 상으로 실행 . 3) Command-Line . Shell 사용해서 실행 . bq mk dataset . 3) REST API . Java나 Python 프로그래밍으로 구현 HTTP 실행 . from google.cloud import bigquery client = bigquery.Client() . 4) Geospatial analytics . Query를 WEB UI 상으로 실행해서 지도에서 표시 . example . 1) table . CREATE OR REPLACE TABLE ecommerce.revenue_transactions_20170801 #schema ( fullVisitorId STRING NOT NULL OPTIONS(description=&quot;Unique visitor ID&quot;), visitId STRING NOT NULL OPTIONS(description=&quot;ID of the session, not unique across all users&quot;), channelGrouping STRING NOT NULL OPTIONS(description=&quot;Channel e.g. Direct, Organic, Referral...&quot;), totalTransactionRevenue FLOAT64 NOT NULL OPTIONS(description=&quot;Revenue for the transaction&quot;) ) OPTIONS( description=&quot;Revenue transactions for 08/01/2017&quot; ) AS SELECT DISTINCT fullVisitorId, CAST(visitId AS STRING) AS visitId, channelGrouping, totalTransactionRevenue / 1000000 AS totalTransactionRevenue FROM `data-to-insights.ecommerce.all_sessions_raw` WHERE date = &#39;20170801&#39; AND totalTransactionRevenue IS NOT NULL #XX transactions ; . 2) view . CREATE OR REPLACE VIEW ecommerce.vw_large_transactions OPTIONS( description=&quot;large transactions for review&quot;, labels=[(&#39;org_unit&#39;,&#39;loss_prevention&#39;)], expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 90 DAY) # 90일 이내 생성된 뷰 조회 ) AS #standardSQL SELECT DISTINCT SESSION_USER() AS viewer_ldap, REGEXP_EXTRACT(SESSION_USER(), r&#39;@(.+)&#39;) AS domain, date, fullVisitorId, visitId, channelGrouping, totalTransactionRevenue / 1000000 AS totalTransactionRevenue, currencyCode, STRING_AGG(DISTINCT v2ProductName ORDER BY v2ProductName LIMIT 10) AS products_ordered FROM `data-to-insights.ecommerce.all_sessions_raw` WHERE (totalTransactionRevenue / 1000000) &gt; 1000 AND currencyCode = &#39;USD&#39; AND REGEXP_EXTRACT(SESSION_USER(), r&#39;@(.+)&#39;) IN (&#39;google.com&#39;) # session user가 google.com 인 경우만 조회 가능 GROUP BY 1,2,3,4,5,6,7,8 ORDER BY date DESC # latest transactions LIMIT 10; . session user 정보 조회 . SELECT SESSION_USER() AS viewer_ldap; . 3) partitioned table . CREATE OR REPLACE TABLE ecommerce.partition_by_day PARTITION BY date_formatted OPTIONS( description=&quot;a table partitioned by date&quot; ) AS SELECT DISTINCT PARSE_DATE(&quot;%Y%m%d&quot;, date) AS date_formatted, fullvisitorId FROM `data-to-insights.ecommerce.all_sessions_raw` . partition expiration 되게 하면 . CREATE OR REPLACE TABLE ecommerce.days_with_rain PARTITION BY date OPTIONS ( partition_expiration_days=60, # 60일 이후에 expire됨 description=&quot;weather stations with precipitation, partitioned by day&quot; ) AS SELECT DATE(CAST(year AS INT64), CAST(mo AS INT64), CAST(da AS INT64)) AS date, (SELECT ANY_VALUE(name) FROM `bigquery-public-data.noaa_gsod.stations` AS stations WHERE stations.usaf = stn) AS station_name, -- Stations may have multiple names prcp FROM `bigquery-public-data.noaa_gsod.gsod*` AS weather WHERE prcp &lt; 99.9 -- Filter unknown values AND prcp &gt; 0 -- Filter AND CAST(_TABLE_SUFFIX AS int64) &gt;= 2018 . for reducing the price . 1) query 하기 전에 preview 사용 (비용 X) 2) 사전에 query result size 체크 (오른쪽 display) 3) maximum billing limit 설정 4) prevent asterisk(*): column oriented storage로 wild card 사용시 column마다 압축 풀어서 가져와야 함 5) partition table 및 clustered index table 사용: random access 줄어듦 6) array 형 사용 7) 적절한 슬롯2 수 사용 ( on-demand / flat-rate pricing ) . . Working with arrays . 참고 . . Cloud Data Fusion . Data pipeline 구축 및 관리 (fully-managed) . . 1) Pipelines create complex data processing workflows (both batch and realtime) using an intuitive UI (Directed Acylic Graph, DAG) . 2) Wrangler connect to data, and transform it using point-and-click transformation steps view, explore, and transform a small sample (10 MB) of your data in one place before running the logic on the entire dataset in the Pipeline Studio . 3) Metadata how datasets and programs are related to each other, full visibility into the impact of changes . 4) Hub distribute reusable applications, data, and code to all users in their organization . Wrangler . 1) create bucket . export BUCKET=$GOOGLE_CLOUD_PROJECT gsutil mb gs://$BUCKET . 2) data copy to bucker . gsutil cp gs://cloud-training/OCBL163/titanic.csv gs://$BUCKET . 3) Wangler로 preprocessing 작업 Google Cloud Storage에 있는 titanic raw가 있는 data 탭으로 가서 먼저 csv parsing을 함 . Preprocessing (CLI) . drop :body # 기존 body(:은 컬럼임) 날리기 fill-null-or-empty :Cabin &#39;none&#39; # Cabin 결측치 처리 send-to-error empty(Age) # Age empty면 에러 처리 parse-as-csv :Name &#39;,&#39; false # Name 컬럼 콤마 기준으로 컬럼을 두개로 나눔 drop Name fill-null-or-empty :Name_2 &#39;none&#39; rename Name_1 Last_Name rename Name_2 First_Name set-type :PassengerId integer parse-as-csv :First_Name &#39;.&#39; false drop First_Name drop First_Name_3 rename First_Name_1 Salutation fill-null-or-empty :First_Name_2 &#39;none&#39; rename First_Name_2 First_Name send-to-error !dq:isNumber(Age) || !dq:isInteger(Age) || (Age == 0 || Age &gt; 125) set-type :Age integer set-type :Fare double set-column Today_Fare (Fare * 23.4058)+1 generate-uuid id mask-shuffle First_Name . wrangler-docs 참고 . more에 가서 view schema 하면 해당 데이터 meta 정보 json으로 추출 가능 . Transformation steps 탭에 있는 다운로드 아이콘 누르면 preprocessing 내역 추출 가능 . 4) insight 탭으로 가서 columns별 데이터 distribution 시각화 된 것 확인 . . Pipelines Studio 내 Wrangler로 작업한 노드의 Properties에 들어가면, Wrangler로 한 작업들의 명세를 확인할 수 있음 . Pipelines . 1) target인 BigQuery에 dataset 미리 생성 (demo_cdf) 2) Data Fusion에서 create pipeline (Batch) 눌러서 Studio 이동 3) Sink 섹션에 있는 BigQuery를 배치해서 pipeline 연결하고 Properties 구성 (dataset: demo_cdf) 4) save 후 deploy 하고, run 5) summary에서 해당 job의 dash board 확인 가능 . elastic storage bins in Google Cloud Storage &#8617; . | parallel processing에 사용되는 virtual CPU 수 &#8617; . |",
            "url": "https://nueees.github.io/techblog/gcp/bigquery/2021/10/02/data-lifecycle-store.html",
            "relUrl": "/gcp/bigquery/2021/10/02/data-lifecycle-store.html",
            "date": " • Oct 2, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Data Lifecycle - Ingest",
            "content": "Cloud Architecture Center . . . 0.1. Orchestration . Cloud Composer . Apache Airflow에 내장된 workflow orchestration service (위 그림 서비스들을 관리) . . 1.1. Ingesting app data . Data from app events, such as log files or user events, is typically collected in a push model, where the app calls an API to send the data to storage. . 1) Writing data to a file Cloud Storage에서 CSV file로 빼내거나 BigQuery로 DW에서 데이터를 뽑거나 . 2) Writing data to a database Cloud SQL 혹은 NoSQL인 Datastore 혹은 Bigtable로 데이터를 씀 . Cloud SQL . Fully managed relational database service for MySQL, PostgreSQL, and SQL Server . Datastore . a highly scalable NoSQL database for your web and mobile applications . Cloud Bigtable . A fully managed, scalable NoSQL database service for large analytical and operational workloads . Cloud Firestore . Easily develop rich applications using a fully managed, scalable, and serverless NoSQL document database . . 1.2. Ingesting streaming data . The data consists of a continuous stream of small, asynchronous messages. . 1) Streaming data as messages streaming 데이터를 Pub/Sub으로 보내서 받은 message를 processing 혹은 storing . Pub/Sub . Real-time messaging and ingestion for event-driven systems and streaming analytics . . 1.3. Ingesting bulk data . Large amounts of data are stored in a set of files that are transferred to storage in bulk. . 1) Scientific workloads Genetics data가 있는 VCF text file을 Cloud Storage에 upload (추후 Cloud Life Sciences로 처리) . 2) Migrating to the cloud on-premise Oracle DB에서 Google Cloud SQL DB로 migration 할 때 . 3) Backing up data Cloud Storage Transfer Service를 통해 replicating해서 백업 할 때 . 4) Importing legacy data 기존 legacy big data를 Bigquery (DW)로 import 할 때 . Cloud Storage . Object Storage . BigQuery . Serverless, highly scalable, and cost-effective multicloud data warehouse designed for business agility .",
            "url": "https://nueees.github.io/techblog/gcp/2021/10/01/data-lifecycle-ingest.html",
            "relUrl": "/gcp/2021/10/01/data-lifecycle-ingest.html",
            "date": " • Oct 1, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Cloud Service",
            "content": "출처_Building Cloud private native 전문가 양성과정 교재 . 8.클라우드 서비스 소개 . 8.1. 클라우드 서비스 개요 . 네트워크를 이용해서 사용자들이 원하는 방식으로 서비스를 제공 | 확장성 | 사용 모델 | 분산 | 개인 시스템의 성능에 구애받지 않음 | . 장점 . 초기 구성 비용 절감 | 초기 구성 시간 절약 | 확장성이 | . 단점 . 오랜 기간 사용할 경우 비용 부담 증가 | . 8.2. 클라우드 서비스 분류 . SaaS (Software as a Service): 서비스로서 소프트웨어 애플리케이션 서비스를 제공 . 보통 IaaS, PaaS위에 올라가고, 중앙에서 호스팅되고 있는 소프트웨어를 웹 브라우저 같은 애플리케이션을 통해 사용 ex) Google Docs . PaaS (Platform as a Service): 서비스로서 플랫폼 소프트웨어를 제공 . SaaS의 개념을 개발 플랫폼으로 확장한 방식 플랫폼(OS)를 웹에서 쉽게 빌려 사용 확장성과 경제적 이유로 On-Premise환경을 Cloud로 확장 ex) Google APP Engine, OpenShift . IaaS (Infrastructure as a service):서비스로서 인프라 자원 제공 . Server, Storage, Network를 가상으로 만들어 사용자가 필요한 자원 사용 관리와 책임이 클라우드 소비자에게 존재 . ex) 대부분 퍼블릭 클라우드 서비스 (AWS EC2, S3) . 8.3. 클라우드 서비스 종류 . Private Cloud . 자체적으로 데이터센터 안에 클라우드 환경 구축 . 자산 스스로 보유, 구축 | 기존 IT 인프라 자원 활용 가능 | 소규모로 구축할 때 비용이 높음 | 보안 서비스를 자체적으로 구축해야 함 | . Public Cloud . 비용을 지불하고 서비스 제공 업체가 구축한 Server, Storage, Network 등 IT Infra 사용 . 공용 클라우드는 가입 형태의 서비스 | 대규모 서비스로 구축 시 비용 절감 | 서비스 제공자가 구축한 보안 서비스 안에서 운용 | . Hybrid Cloud . 공용 + 사설 클라우드의 장점만 선택해서 사용 . 필요에 의해 데이터나 컴퓨팅 자원의 위치 조절 | 데이터의 중요도와 비즈니스 핵심 업무 여부에 따라 선택 가능 | .",
            "url": "https://nueees.github.io/techblog/kubernetes/2021/09/04/cloud-service.html",
            "relUrl": "/kubernetes/2021/09/04/cloud-service.html",
            "date": " • Sep 4, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Container Cluster Kubernetes",
            "content": "출처_Building Cloud private native 전문가 양성과정 교재 . 5.Container Cluster . 5.1.Kubernates 소개 . docker - 단일 시스템에서만 다수의 컨테이너 관리 -&gt; 다수의 시스템과 애프리케이션 설정을 쉽게 설정하고 유지보수할 수 있는 방식인 오케스트레이션(Ochestration)이 필요 kubernates - 구글에서 개발된 컨테이너 오케스트레이션 도구 . 다중 컨테이너 관리를 위한 docker-compose를 설치해야 함. . 쿠버네티스는 클러스터 구성해서 오케스트레이션을 통해 컨테이너를 자동으로 관리, 2개 이상 시스템에서 관리 가능 관리 대상을 object라고 함 - pods(컨테이너 단위)와 controller(pods를 한번에 관리)로 구성(application workload) . 기능 . 컨테이너 플랫폼, 마이크로서비스 플랫폼, 이식성있는 클라우드 플랫폼 제공 . Automatic Binpacking | Storage Orchestration | Secret &amp; Configuration Management | Horizontal Scaling | Service Discovery &amp; Load Balancing | Self Healing | Batch Execution | Automatic Rollbacks &amp; Rollouts | . CI/CD 파이프라인, 애플리케이션 레벨의 서비스, 로깅, 모니터링, 경고 솔루션 등을 제공하지 않음 . . 사전 설치 . choco 패키지 관리도구 설치 | $ Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager ]::SecurityProtocol = [System.Net.ServicePointManager ]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(&#39;[https://community.chocolatey.org/install.ps1&#39;](https://community.chocolatey.org/install.ps1&#39;))) | vagrant 설치혹은 vagrant.exe 파일 다운로드 후 설치 가능 | $ choco install vagrant | 하이퍼바이저 설치 virtualbox 설치 (확장팩) | vagrant 명령어로 구성요소 설치 vagrant plugin install vagrant-hostmanager vagrant plugin install vagrant-disksize 확인: vagrant plugin list윈도우의 경우 직접 작성하면 확장자이름이 자동설정될 수 있으니 주의 | $ vagrant box add ubuntu /bionic64 $ vagrant up =&gt; Vagrantfile 이 있는 곳에서 실행 | 가상머신에 쿠버네티스 배포 ssh 설정 | $ ssh-keygen $ ssh-copy-id node1 (노드 모두 입력) localhost 도 설정 | . kubenates 설치 . 1. 패키지 및 git 설치 $ sudo apt update $ sudo apt upgrade -y $ sudo apt install -y python3 python3-pip git $ git clone --single-branch --branch release-2.14 https://github.com/kubernetes-sigs/kubespray.git $ cd kubespray/ $ sudo pip3 install -r requirements.txt` 2. 인벤토리 수정 $ cp -rfp inventory/sample/ inventory/mycluster $ vim inventory/mycluster/inventory.ini [all] node1 ansible_host=192.168.56.21 ip=192.168.56.21 node2 ansible_host=192.168.56.22 ip=192.168.56.22 node3 ansible_host=192.168.56.23 ip=192.168.56.23 controll-plane ansible_host=192.168.56.11 ip=192.168.56.11 [all:vars] ansible_python_interpreter=/usr/bin/python3 [kube-master] controll-plane [etcd] controll-plane [kube-node] node2 node3 node1 [calico-rr] [k8s-cluster:children] kube-master kube-node calico-rr` $ sudo vim /etc/hosts 192.168.56.11 controll-plane.example.com controll-plane 192.168.56.21 node1.example.com node1 192.168.56.22 node2.example.com node2 192.168.56.23 node3.example.com node3 $ vim inventory/mycluster/group_vars/k8s-cluster/addons.yml metrics_server_enabled: true ingress_nginx_enabled: true metallb_enabled: true metallb_ip_range: - &quot;192.168.56.50-192.168.56.99&quot; metallb_protocol: &quot;layer2&quot; $ vim inventory/mycluster/group_vars/k8s-cluster/k8s-cluster.yml kube_proxy_strict_arp: true 3. 플레이북 실행 $ ansible-playbook -i inventory/mycluster/inventory.ini cluster.yml -b` 4. kubectl 설치 $ curl -LO &quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&quot; $ curl -LO &quot;https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256&quot; $ echo &quot;$(&lt;kubectl.sha256) kubectl&quot; | sha256sum --check $ sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl $ kubectl version --client` . . 5.1.Architecture . . kube-api-server를 통해서 대부분의 작업을 함 kube-controller-manager : on-premise 환경에서 각 리소스 관리 cloud-controller-manager : cloud 환경에서 밴더사 자체적으로 관리 . 마스터(master) . cluster를 구성하기 위한 핵심 요소들의 모음 cluster 조정을 위한 control plane 제공 노드에 작업 분배하는 scheduling 작업 cluster evnet 감지하고 대응 운영환경에서는 multi master 환경을 구성 (FT) . 1) API 서버(kube-apiserver) kubernetes API를 노출하는 component kubernetes object 관리, 제어를 위한 front-end . 2) etcd cluster의 meta 정보 정장 key-value 형태로 저장 cluster configuration 정보 보관하고 있으므로 백업 필수 . 3) scheduler cluster 내 생성되는(혹은 배정되지 않은) pod를 감지하고 그것을 구동할 노드를 선택 resourse 상태, HW/SW/Policy 제약, Affinity 등 다양한 기준에 따라 배치 결정 . 4) cube-controller-manager . node controller: 노드 관리, 노드 다운시 대응 | replication controller: 복제 컨트롤러를 사용하는 모든 object관리, 적정 pod 수 유지 | endpoint controller: service와 pod 연결 (물리적 시스템과 컨테이너 내부 어플리케이션 연결) | service account &amp; token controller: 쿠버네티스 namespace, account, token 등 인증 관련된 것 담당 | . 5) cloud-controller-manager . AWS, GCP 등 각 밴더 별 클라우드 서비스 관리 . node controller: 노드 관리, 노드 다운시 대응 | route controller: 클라우드 환경의 네트워크 경로 | service controller: 클라우드 로드밸런서 관리 | volume controller: 클라우드 볼륨 관리 | . 워커 노드(worker node) . container를 실행하고 동작중인 Pods 유지시키고 kubernetes runtime 환경 구성 (minion이라고도 함) . 1) kubelet 각 노드에서 실행되는 agent로 마스터로부터 제공받은 구성 정보, 노드가 수행해야할 작업 동작 . 2) kube-proxy 네트워크 규칙 유지하고 연결에 대한 포워딩 수행하므로써 서비스 추상화 가능하게 함 컨테이너에 연결될 네트워크 구성 관리 . 3) container runtime 실제 컨테이너 동작을 책임지는 구성요소 . Docker | containerd | CRI-O | rktlet | Kubernetes CRI(Container Runtime Interface) | . 추가 요소(add-on) . 구성요소 설명 . 클러스터 DNS | 쿠버네티스 클러스터 내의 여러 오브젝트에 대하여 주소기반으로 오브젝트를 접근할 수 있는 DNS 제공 | . DashBoard | 모니터링 용 웹기반 인터페이스 | . 컨테이너 resource 모니터링 | 컨테이너 리소스 사용량의 시계열 매트릭스 기록 | . 클러스터 logging | 컨테이너 로그를 중앙로그저장소에 저장하고 관리, 로그를 검색/열람하는 인터페이스 제공 | . 쿠버네티스 API . 1) API 버전 규칙 alpha 버전 API : 개발 초기 버전 beta 버전 API : 일정 수준 이상 테스트가 된 버전 stable 버전 : vX 형태의 안정화된 버전 . 2) API 그룹 core group: apiVersion:[version] core 이외 group: apiVersion: [group]/[version] . . 5.3.Menifest . 필드 설명 . apiVersion | object를 생성하기 위한 API 버전을 지정 | . kind | object 종류 | . metadata | name, label, namespace 등 기본정보 | . spec | object 세부 상태 | . Managing Object . 1) Imperative commands(명령형 커맨드) 재사용성이 떨어져 개발 환경에서 테스트 시, 일회성 작업일 경우 사용 . $ kubectl run nginx --image nginx . 2) Imperative object configuration(명령형 오브젝트 구성) yaml, json 포맷으로 파일을 작성하여 kubectl은 작성된 파일을 참고하여 실행 . $ kubectl create -f nginx.yaml . 3) Declarative object configuration(선언형 오브젝트 구성) 특정 디렉토리에 오브젝트 파일을 배치하고 작성된 파일을 참고하여 오브젝트 관리 . $ kubectl diff -f configs/ $ kubectl apply -f configs/ . Running App with Imperative commands 예시 . $ kubectl run mytest-app --image=&lt;ACCOUNT&gt;/myweb --port=8080 --generator=run/v1 # 레플리케이션 컨트롤러(pod) 생성 $ kubectl get pods $ kubectl get replicationcontrollers $ kubectl expose replicationcontroller mytest-app --type=LoadBalancer --name myweb-svc # 서비스 생성 $ kubectl get services $ curl http://192.168.56.11:31289 $ kubectl scale replicationcontroller mytest-app --replicas=3 $ kubectl get pods $ kubectl get replicationcontrollers $ curl http://192.168.56.11:31289 $ kubectl get all $ kubectl delete replicationcontrollers mytest-app $ kubectl delete service myweb-svc . . 6.Application Workload . 6.1.Pods . 도커에서 작업을 수행하기 위해 구동해야 하는 가장 작은 단위는 컨테이너 쿠버네티스 클러스터 내에서 애플리케이션 배포하며 동작하는 단위 1 컨테이너 = 1 애플리케이션 하나의 Pod는 하나의 node에서만 동작 동일한 Pod 의 모든 컨테이너는 동일한 리소스와 로컬 네트워크를 공유하여 머신이 분리되어 있어도 pod 내 컨테이너 간 통신이 가능함 쿠버네티스 클러스터는 여러 개의 노드로 구성되며 각 노드는 컨테이너를 구동할 수 있도록 준비하고 있으나, 하나의 파드에 두개 이상의 컨테이너가 포함된 경우 각 컨테이너를 여러 노드에 분산시켜서 실행할 수는 없음. 1 pod 내 있는 컨테이너는 저장소, 네트워크 IP 등 공유 . Pod 정의: YAML 파일 생성 | cat testapp-pod.yml . . 기본적인 apiVersion, kind, metadata, spec 포함 - 하이픈 기호는 리스트(List)를 의미 . Pod 생성 및 확인 | $ kubectl create -f testapp-pod.yml $ kubectl get pods $ kubectl get pods testapp-pod -o yaml(-o json) $ kubectl discribe pods testapp-pod $ kubectl logs testapp-pod # 로그 확인 $ kubectl port-forward testapp-pod 8080:8080 # 포트포워딩 $ curl http://localhost:8080 | Label(레이블) 및 Selector(셀렉터) Label: 쿠버네티스 클러스터의 모든 오브젝트에 키/값 쌍으로 이루어진 값을 설정하여 리소스 식별, 속성 지정 역할 네임스페이스 내 중복 불가 Label Selector: Label을 식별하고 검색함 | cat testapp-pod-label.yml . . Anotation(어노테이션) 오브젝트의 추가 정보를 기록하는 경우 사용하는 주석 | $ kubectl annotate pods testapp-pod devops-team/developer=&quot;nueees&quot; | Name Space(네임스페이스) Name Space: 쿠버네티스 클러스터 내 오브젝트와 리소스를 용도와 목적에 따라 논리적으로 완전히 분리된 환경default: 기본 네임스페이스 kube-node-lease: 쿠버네티스 노드(마스터/노드)의 가용성 체크를 위한 네임스페이스 kube-public: 모든 사용자 접근가능 kube-system: 클러스터의 리소스가 배치되는 네임스페이스 | $ kubectl get namespaces | Liveness Prove(라이브니스 프로브) 파드 상태가 정상적인지 주기적으로 모니터링 서비스 | HTTP GET Prove: 특정 경로에 HTTP GET 요청, HTTP 응답코드가 2XX/3XX인지 확인 | TCP Socket Prove: 특정 TCP port 연결 시도 | Exec Prove: 컨테이너 내부의 바이너리(명령)를 실행하고 종료 코드 확인 cat testapp-pod-liveness.yml | . $ kubectl create -f testapp-pod-liveness.yml . . 6.2.Controller . 사용자가 의도한 상태로 유지 해 주는 기능 . Deployment . stateless Application 배포 시 사용 Applicaion은 컨테이너 집합인 Pod 단위로 배포 사용자의 기대상태(Desired state)를 유지하도록 하는 controller . Liveness Probe: 응답 체크 | Readlness Probe: 서비스 가능 상태 체크 ReplicaSet에 대한 Update 담당 | . use case: . 신규 ReplicaSet을 생성하여 Pod를 새로운 버전으로 점진적 교체 수행 (Rolling Update) | Application configuration 분리 (Decoupling): Config Map | . ReplicaSet (레플리카셋) . 사용자가 요구하는 복제본 개수만큼 Pod를 복제하고 관리하는 기능 주로 Deployment 의 spec 으로 정의하는 것을 권장함 관리해야 하는 pod을 식별하기 위한 selector, 유지해야 하는 pod의 개수, pod template 포함 . Pod의 다중 레이블 조건 지원 | Pod에 설정된 레이블의 키 조재 여부 조건 선택 가능 | . cat testapp-rs.yml . . $ kubectl create -f testapp-rs.yml $ kubectl get replicasets.apps . cat testapp-rs-exp.yml . . $ kubectl create -f testapp-rs-exp.yml $ kubectl get replicasets.apps -o wide . DaemonSet (데몬셋) . 쿠버네티스 클러스터는 부하 분산, 이중화를 통한 장애 대응 목적 등을 위하여 최소 하나 이상의 노드로 구성되므로 다수의 노드를 사용할 경우 필요에 따라 각 노드별*로 특정 목적을 수행하는 *파드를 한 개씩 배치하여야 하는 경우 발생 . 레플리카셋과 비슷하지만 복제본을 지정하지 않음 . cat testapp-ds.yml . . nodeSelector에 Pod가 배포될 노드 선택 . $ kubectl create -f testapp-ds.yml $ kubectl get replicasets.apps -o wide $ kubectl label nodes kube-node1 node=development # node에 label지정 $ kubectl label nodes kube-node1 --show-label . StatefulSet . Pod이 스케줄 될 때 지속적으로 유지되는 식별자를 가질 수 있도록 관리하는 object use case: 고유한 네트워크 식별자, 지속성을 갖는 스토리지(persistent volumes), 순차적 배포와 스케일링, 순차적인 자동 . . 7.Network - Service . 7.1. Service 생성 . Service: 쿠버네티스 시스템에서 같은 애플리케이션을 실행하도록 구성된 컨트롤러에 의해 생성된 Pod 그룹에 단일 네트워크 진입점 제공 . 서비스에 부여된 IP는 해당 서비스가 종료될 때까지 유지하고 클라이언트는 이 서비스에 부여된 고정 IP 및 PORT를 통해 Pod에 접근 가능 | 클러스터 내 Pod들에게 접근하기 위한 방법으로 사용 | 여러 Pod를 묶어 Healthy한 Pod로 Traffic 라우팅하는 로드 밸런싱 기능 제공 | 클러스터의 Service CIDR 중에서 지정된 IP로 생성 가능 | 서비스 이름은 클러스터내 고유한 DNS로 동작 | . cat testapp-svc.yml . . $ kubectl create -f testapp-svc.yml $ kubectl get services # 진입점인 서비스 $ kubectl get endpoints testapp-svc # 엔드포인트 -&gt; 레플리카셋 컨트롤러의 파드 . 엔드포인트: 최종 목적지인 파드의 주소 및 포트 정보 . $ kubectl run nettool -it --image= &lt;ACCOUNT &gt;/network-multitool # 서비스 접근 테스트 . Session Affinity: 클라이언트가 특정 파드(웹서비스) 요청 시 이전에 처리된 파드로 동일하게 전달하여 처리 . cat testapp-svc-ses-aff.yml . . $ kubectl create -f testapp-svc-ses-aff.yml . Configuring Service Multi-Port . Pod는 하나 이상의 컨테이너로 구성되어 있어서, 각 컨테이너는 서로 다른 포트 사용 가능 . cat testapp-svc-multiport.yml . . $ kubectl create -f testapp-svc-multiport.yml . Configuring Service by named-port . 레플리카셋 컨트롤러의 Pod 템플릿에서 생성될 컨테이너의 포트에 이름을 부여하여 포트 이름 구성 가능 . cat testapp-rs-named-port.yml . . cat testapp-svc-named-port.yml . . $ kubectl create -f testapp-rs-named-port.yml -f testapp-svc-named-port.yml . 7.2. Service 탐색 . kubectl get 명령어로 IP 주소를 수동적으로 확인할 수 있지만 Object끼리 통신을 위한 방식 필요 . 환경변수 방식 | 쿠버네티스 클러스터 내 DNS 사용 방식 | DNS를 이용한 Service 탐색 . kube-systme 네임스페이스에서 쿠버네티스에 등록된 구성요소 확인 가능 그중 k8s-app=kube-dns 레이블 옵션을 통해 DNS 관련 파드 확인 . 1) DNS 관련 리소스 확인 . $ kubectl get all -n kube-system -l k8s-app=kube-dns . 2) 파드 내부 DNS 설정 확인 이름 기반의 주소로 네트워크에 접근하기 위해서 DNS 설정 필요 . $ kubectl exec testapp-rs-m65m4 -- cat /etc/resolv.conf # 위의 coredns 서비스 IP와 다름 . 각 파드의 DNS로 등록되어 있는 위 IP(169.254.0.0/16 형식)는 IPv4 주소형식에서 ‘Link Local Address’이며, 유효한 IP 주소가 아님 3) NoceLocal DNSCache 해당 주소(169.254.25.10)는 coreDNS로 직접적으로 요청이 전달되지 않게 하는 중간 단계 캐시 DNS DaemonSet 형태로 쿠버네티스의 각 노드마다 DNS 캐시 기능을 하는 Pod 배치하여 필요한 경우에만 CoreDNS 호출하는 구조 . Pod &lt;-&gt; NodeLocal DNSCache &lt;-&gt; iptables &lt;-&gt; coreDNS . $ kubectl get daemonsets.apps -l k8s-app=kube-dns -n kube-system # 각 노드별 데몬셋 컨트롤러 확인 $ kubectl get pods -l k8s-app=kube-dns -n kube-system | grep -A 2 Args # node local dns 확인 $ kubectl run nettool -it --image= &lt;ACCOUNT &gt;/network-multitool --generator=run-pod/v1 --rm=true bash # 서비스 접근 테스트 . 주소구성: &lt;리소스(서비스) 이름&gt;... . 7.3. Service 종류 . 위의 내용은 내부 접근이고, 외부 접근 제공하는 서비스 구성 필요 . ClusterIP: 클러스터 내부용 진입점 제공 . NodePort: 쿠버네티스 각 노드(호스트)의 포트를 외부 접근용으로 할당 . LoadBalancer: NodePort의 확장판으로, 외부 로드밸러서로 접근하면 서비스를 통해 파드로 Redirection . ExternalName: 외부에서 접근하기 위한 서비스 유형이 아닌, CNAME 매핑을 통해 특정 FQDN과 통신을 위한 기능 . 외부 접근용 레플리카셋 생성 및 확인 | $ kubectl create -f testapp-rs.yml $ kubectl get replicasets.apps $ kubectl get pods | NodePort 서비스 생성 cat testapp-svc-ext-nodeport.yml | $ kubectl create -f testapp-svc-ext-nodeport.yml # 해당 노드에서 사용할 포트 31111로 지정 $ kubectl get endpoints testapp-svc-ext-np # 서비스의 엔드포인트 확인 (Pod의 8080 포트로 Redirection 됨) $ kubectl get nodes -o wide # 각 노드의 IP 확인 | LoadBalancer 서비스 생성 cat testapp-svc-ext-loadbalancer.yml | $ kubectl create -f testapp-svc-ext-loadbalancer.yml # 해당 노드에서 사용할 포트는 정의하지 않음 $ kubectl get services # LoadBalancer 서비스 확인 | ExternalName 서비스 생성 cat testapp-svc-ext-externalname.yml | $ kubectl run nettool -it --image= &lt;ACCOUNT &gt;/network-multitool --generator=run-pod/v1 --rm=true bash # 서비스 접근 테스트 $ nllookup testapp-svc-extname-gl | $ kubectl create -f testapp-svc-ext-externalname.yml # FQDN은 google이며 이에 대한 CNAME은 testapp-svc-extname-gl $ kubectl get services # ExternalName 서비스 확인 | .",
            "url": "https://nueees.github.io/techblog/kubernetes/2021/09/03/kubernetes.html",
            "relUrl": "/kubernetes/2021/09/03/kubernetes.html",
            "date": " • Sep 3, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Docker Image Build",
            "content": "출처_Building Cloud private native 전문가 양성과정 교재 . 3.Building Docker Image . Dockerfile . # docker run -it --name c1 centos # yum -y install httpd &gt; /dev/null ## systemctl start httpd ## systemctl enable httpd # httpd 이미지는 CentoOS와 호환되지 않아 설치 시 오류 발생 # docker inspect centos # container boot시 명령어가 지정되어 있음 ( &quot;Cmd&quot;: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;#(nop)&quot;, &quot;CMD [ &quot;/bin/bash &quot;]&quot;...) # dodker inspect httpd # ( &quot;Cmd&quot;: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;#(nop)&quot;, &quot;CMD [ &quot;httpd-foreground &quot;]&quot;...) . 이 경우 직접 컨테이너를 구동하고 수정하는 방식으로는 특정 어플리케이션 지정할 수 없음 Dockerfile을 사용해야 함 . Dockerfile 생성 . # mkdir dftest1 # cd dftest1 # vi Dockerfile FROM httpd:latest MAINTAINER nueees RUN yum -y install httpd COPY index.html /var/www/html CMD /usr/sbin/httpd -D FORGROUND # docker build -t test:1.0 . # 현재 디렉토리(.)로 빌드 # docker images # test:1.0으로 추가된 것 확인 . base image (베이스 이미지) | command (실행 명령) | env (환경 변수) | run (실행 데몬) | 명령어 설명 . FROM | 베이스 이미지 지정 | . MAINTAINER | 작성자 지정 | . RUN | 명령어 실행 | . CMD | 데몬 실행 | . LABEL | 라벨 지정 | . EXPOSE | 포트 내보내기 | . ENV | 환경변수 설정 | . ADD | 파일 추가 | . COPY | 파일 복사 | . VOLUME | 볼륨 마운트 | . ENTRYPOINT | 데몬실행 | . USER | 사용자 설정 | . WORKDIR | 작업 디렉토리 설정 | . ONBUILD | build 후 실행 명령 | . . Docker image build . # docker build -help # cat /root/file/Dockerfile # docker build -t base:1.0 /root/file/ # docker images . docker layer 구조 . # docker build -t base:1.0 /root/file # 실행시 레이어 구조가 하나씩 나옴 . setp 1/5 : FROM centos | step 2/5 : MAINTAINER nueees | step 3/5 RUN yum -y install httpd | step 4/5 COPY index.html /var/www/html | step 5/5 CMD /usr/sbin/httpd -D FORGROUND | . 4.Docker Image Registry . Docker image registry? . Registry - Docker Image Registry . 도커 허브에 공개되어 있는 registry 공식 이미지 . # docker search registry # docker pull registry:2.0 # docker images # docker run -d -p 5000:5000 --name regTest registry:2.0 # docker tag httpd localhost:5000/regTest # docker push localhost:5000/regTest # upload # docker rmi localhost:5000/regTest # docker pull localhost:5000/regTest # download # docker images . Harbor - Docker Image Registry . one of private registries web 기반, 다양한 기능 제공 . docker-compose 설치 . # curl -L &quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose # chmod +x /usr/local/bin/docker-compose # docker-compose --version . Harbor 설치 파일 download . # wget &quot;https://github.com/goharbor/harbor/releases/download/v2.3.3/harbor-offline-installer-v2.3.3.tgz&quot; # tar xzvf harbor-offline-installer-version.tgz . HTTPS 구성 후 . Configuration File(YML File) 수정 . # vi harbor.yml 5 hostname: docker.nueees.co.kr 13 https: 15 port: 443 17 cerificate: 18 private_key: . Harbor 설치 . # systemctl restart docker # ./install.sh . Harbor 사용 . # docker login -u admin -p Harbor12345 192.168.56.101 # docker tag centos:latest 192.168.56.101/library/docker:centos # docker push 192.168.56.101/library/docker:centos # docker rmi 192.168.56.101/library/docker:centos # docker pull 192.168.56.101/library/docker:centos . 웹에서 Harbor IP 접속하여 대시보드 확인 . .",
            "url": "https://nueees.github.io/techblog/kubernetes/2021/09/02/docker-image-build.html",
            "relUrl": "/kubernetes/2021/09/02/docker-image-build.html",
            "date": " • Sep 2, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Docker Container Configuration & management",
            "content": "출처_Building Cloud private native 전문가 양성과정 교재 . 1.Docker Container . Container &amp; Virtualization . 하드웨어 성능이 올라가면서, 유휴자원을 활용하는 가상화(자원을 나눠서 사용) 기술이 대두됨. . 가상화 종류 . Hypervisor Virtualization(Native/Bare Metal): 하드웨어 위에 OS 대신 하이퍼바이저를 설치하고 가상(개별OS)머신 생성 (Hyper-V,XenServer) | Host Virtualization: 하드웨어 위에 OS 설치하고, 하이퍼바이저 설치 후, 가상(개별OS)머신 생성 (VMware, VirtualBox) | Container Virtualization: 하드웨어 위에 OS설치하고, 컨테이너 runtime 관리 S/W 설치 후 가상(App)머신 생성 (Docker) 개별운영체제X, 호스트 OS의 일부를 공유하는 방식 사용, overhead 적음 | 그밖에 Application/Network/Storage Virtualization 있음. | . Docker Architecture . Docker’s strengths . don’t need a guest OS | Transplant : easily ported across different platforms | support On-Premise, Cloud, and DevOps open source | . Docker’s main function . Image 생성/관리 image는 컨테이너 구동을 위한 데이터 생성시 코드로 기술 가능(Infrastructure as Code, IaC) | Image 공유 Registry는 Image의 저장소 (Ubuntu, Debian, CentOS, Fedora의 기본 이미지, 다양한 소프트웨어 탑재 된 이미지 제공) 다운로드, 업로드, 버전 관리 가능 | Container 운영 이미지 상태의 파일 -&gt; 프로세스로 띄움 시작, 중지, 삭제 작업 | . 컨테이너 간 간섭을 방지하기 위해 Isolation 기술 (리눅스 namespace와 cgroup 기능) 사용 . technique for Docker : 리눅스 커널 . 독립된 환경 네임스페이스(namespace) 네임스페이스 별로 독립된 PID, Network, UID, MOUNT, UTS, IPC 사용 | 제어그룹 (cgroup) Process 또는 Thread를 그룹화 하여 관리 - CPU나 Memory를 그룹별로 제한 가능 | 가상 Bridge와 가상 NIC(Network Interface Card) 컨테이너 별 각각의 가상 NIC가 할당(ContainerA - eth0, ContainerB - eth0) 가상 NIC는 docker0(172.17.0.0/16)라는 가상 bridge로 연결되어 컨테이너끼리 또는 호스트(물리NIC)를 통해 외부 네트워크로 연결 (Host - eth0) | 계층 파일 시스템 기본 컨테이너 이미지에 추가 작업 시 COW(Copy on Write)* 방식으로 생성 COW 방식은 부모 프로세스가 자식 프로세스를 생성할 때 전부 복제하지 않고, 쓰기가 발생했을 때 변경된 부분만 복제하는 방법과 유사 도커 이미지관리에 사용되는 FS or Library : Btrfs, AUFS, Device Mapper, OverlayFS | . . 2.Managing Docker Container . Installing Docker Engine . 도커 패키지 리포지토리 연결 및 설치 . # yum install -y yum-utils # 필요 util 설치 # yum-config-manager --add-rep https://download.docker.com/linux/centos/docker-ce.repo # 도커 구성 매니저 설치 # yum repolist # yum -y install docker-ce docker-ce-cli containerd.io # 도커 설치 # yum list docker-ce # systemctl start docker.service # 서비스 시작 # systemctl enable docker.service # systemctl is-active docker.service # docker --help . Docker container image . 도커 이미지 관리 . # docker search --help # docker search centos -s 1000 # repository에서 centos 검색 # docker pull --help # docker pull centos # repository에서 centos 가져오기 # docker images # docker tag --help # docker tag centos:latest centos:ver7 # centos 태그 latest-&gt;ver7로 변경 # docker rmi --help # docker rmi centos # centos image 제거 # docker image prune # 이름없는 dangling 이미지 제거 # docker login # docker tag centos:latest nueees/repo-web:centos # docker push --help # docker push nueees/repo-web:centos . . Docker container management . 도커 컨데이너 관리 . # docker create --help # docker create -it --name c1 centos # centos 이미지로 c1라는 컨테이너 생성 # docker ps --help # docker ps -a # docker inspect --help # docker inspect c1 # # docker start --help # docker start c1 # docker stop --help # docker stop c1 # docker run --help # docker run -it --name c2 centos # docker run -d --name web1 httpd # docker rm -f web1 . run (create+start) exit -&gt; 컨테이너 종료 Ctrl+P+Q -&gt; 컨테이너 종료하지 않고 빠져나옴 . # docker attach --help # docker run -itd --name c1 centos # docker attach c1 # background에 실행중인 c1 컨데이너 접근 # docker exec --help # docker run -d --name web1 httpd # docker exec -it web1 bash # web1 컨테이너 접근해서 bash 실행 # docker top --help # docker top web1 # web1 컨테이너에서 실행중인 process 확인 # docker top web1 aux # docker rename --help # docker rename c1 newc1 # docker pause --help # docker pause web1 # docker unpaues web1 # docker cp --help # docker run -itd --name c1 centos # docker cp dockercp.txt c1:/ # host file -&gt; container c1의 /경로로 copy # docker exec -it c1 cat /dockercp.txt # docker diff --help # docker attach c1 ## rm -f anaconda-post.log # 기존 컨테이너 내 log 삭제 후 # docker diff c1 # docker commit --help # docker commit c1 centos:hello # 기존 c1 container로 new image 생성 # docker images # docker save --help # 여러개 이미지를 archive file로 저장 시 # docker save -o imgarc.tar centos:hello httpd:latest # centos:hello, httpd 두개 image를 archive file로 저장 # docker load --help # docker load -i imgarc.tar # archive file에 저장된 이미지 불러오기 # docker images # 불러온 이미지 확인 # docker export --help # 컨테이너 파일시스템을 archive file로 추출 # docker attach c1 ## echo &quot;This is export test&quot; &gt; export.txt # docker export -o testexport.tar c1 # tar tf testexport.tar | grep export.txt # docker import --help # export로 컨테이너로 추출한 archive file로 이미지로 생성 # docker import testexport.tar export:test . 컨테이너 네트워크 구성 . # ip a s # brctl show # docker run -itd --name c1 centos # brctl show # docker attach c1 ## yum -y install net-tools ## ifconfig ## rount -n # docker0는 172.17.0.0/16 네트워크 사용하고 외부 통신 가능 ## ping -c2 google.co.kr # iptables -L -t nat # 게이트웨이 172.17.0.1이며 마스커레이딩 설정 됨 # docker network --help # docker network ls # 도커 네트워크는 bridge, host, none 세가지 # docker inspect bridge # docker network create --help # docker network create d-net # bridge 유형으로 도커 네트워크 생성 # docker inspect d-net # 네트워크 범위(subnet) 자동으로 172.18.0.0/16으로 설정 # docker network create --subnet 192.168.0.0/24 --gateway 192.168.0.254 custom-net # docker run -it --net custom-net --name a1 alpine # 사용자 정의 custom-net 네트워크 사용하여 컨테이너 생성 # docker run -it --net host --name a2 alpine # host 유형으로 생성시 host 네트워크를 공유 ## ifconfig # docker run -it --net none --name a3 none alpine # none 유형은 네트워크 할당 안함 ## ifconfig . 컨테이너 통신 . # docker run -itd --name a1 alpine # docker run -itd --name a2 --link a1 alpine # docker attach a2 ## ping a1 # ping 감 # docker attach a1 ## ping a2 # ping 가지 않음 # docker exec a1 cat /etc/hosts # docker exec a2 cat /etc/hosts # a1이 등록된 걸 확인 # docker run -itd --name a3 --link a1:alpine1 alpine # 별칭으로 링크 등록 # docker exec a1 ping alpine1 # ping 감 # docker exec a3 cat /etc/hosts # a1과 alpine1으로 등록된 걸 확인 # docker run -d --name web1 httpd # curl localhost # container에서는 80포트가 열려있으나 실제 host의 주소로 접근 불가 # docker run -d -p 80:80 --name web2 httpd # host의 port 80으로 요청오면 container 80으로 전달 (호스트:컨테이너) . 호스트의 특정 포트가 컨테이너 포트와 연결되어 있으면 해당 포트는 다른 컨테이너와 연결될 수 없음. . 컨테이너 볼륨 . # mkdir volume # echo hello &gt; volume/hello.txt # docker run -it -v /boot/volume:/mnt --name v1 centos # host 디렉토리를 container와 공유 (호스트:컨테이너) ## ls /mnt ## cat /mnt/hello.txt ## df -h # /mnt 디렉토리가 host의 /dev/sda1에 연결되어 있음 # mkdir vol1 vol2 vol3 # docker run -it -v /boot/vol1:/vol1 -v /boot/vol1:/vol1 -v /boot/vol1:/vol1 --name v2 centos # 동시에 다수 볼륨도 연결가능 # docker run -it -v /boot/vol1:/vol1 --name c2 centos # 하나 볼륨을 동시에 Read-Write시 crash 발생 # docker run -it -v /boot/vol1:/vol1:ro --name c3 centos # 볼륨 공유시엔 하나 외 나머지는 Read-Only로 ## touch /vol1/xxx # docker run -it -v vol-1:/vol1 --name c1 centos # host에서 디렉토리 생성없이 docker volume 생성 후 연결 (도커볼륨:컨테이너) ## touch /vol1/x # docker run -it -v vol-1:/vol1 --name c2 centos ## ls /vol1 # 파일 x 확인 가능 # docker volume ls # docker 볼륨 확인 # docker inspect vol-1 # 실제로는 host 디렉토리 사용 # docker volume create --help # docker volume create vol2 # 수동으로도 생성 가능 # docker run -it --name m1 mysql # docker inspect m1 # 도커 볼륨을 자동으로 생성하는 이미지가 있음 (&quot;Volumes&quot;:{...) # docker volume ls # 생성된 볼륨 확인 . 컨테이너 환경변수 설정 . # docker run -it -e a=100 --name c1 centos ## echo $a # docker run -it --name db1 mysql # error 출력되며 env 설정 필요 # docker ps -a # docker inspect db1 # (&quot;Entrypoint&quot;:[...) # docker run -d -e MYSQL_ROOT_PASSWORD=1234 --name db2 mysql # 환경변수 주고 실행 . 보통 inpsect 내 “Cmd”:[“mysql”]가 실행되나, Entrypoint가 지정되어 있으면 “Entrypoint”:[“docker-entrypoint.sh”]이 우선 실행됨 . 컨데이너 로그 확인 . # docker logs --help # docker logs db1 # 위 환경변수 오류 error log 확인 가능 # docker logs --tail 2 db2 # docker logs --since &quot;2021-10-12T01:00&quot; db2 . 컨테이너 자원 할당 . # docker run -d --name web1 httpd # options 없이 자원 할당 # docker stats web1 # 최대치 할당 # docker run -d --name web2 --memory=&quot;200m&quot; httpd # docker stats --no-stream web1 # 메모리 limit 200MB # # docker update --help # docker update --memory=500m web2 # up가능하나 down은 불가 # docker run -itd -c 10 --name a1 alpine # 가중치 1로 할당 # docker run -itd -c 20 --name a2 alpine # 가중치 2로 할당 # docker attach a1 ## dd if=/dev/zero of=/dev/null &amp; # docker attach a2 ## dd if=/dev/zero of=/dev/null &amp; # docker stats # cpu 사용률 a2가 a1의 두배 확인 # docker run -itd --name a3 -cpus=&quot;0,2&quot; alpine ## dd if=/dev/zero of=/dev/null &amp; # docker stats # a3의 cpu 사용률 20% 확인 # docker run -itd --name c1 --devie-write-bps /dev/sda:1mb centos # sda 디스크에 write작업시 속도 limit을 1MB/s # docker attach c1 ## dd if=/dev/zero of=/perftest bs=1M count=10 oflag=direct # docker run -itd --name c2 centos # 제한없이 # docker attach c2 ## dd if=/dev/zero of=/perftest bs=1M count=10 oflag=direct . CPU, Memory, Block 제한은 가능하나 NET I/O는 제한 불가 . 워드프레스 컨테이너 실행 example . # docker network create wp-web # 네트워크 생성 # docker run -d --name wp-db --net wp-net -v wp-db-vol:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=1234 -e MYSQL_DATABASE=wordpress -e MYSQL_USER=wordpress -e MYSQL_PASSWORD=1234 mysql:5.7 # docker run -d --name wp-web --net wp-net -v wp-web-vol:/var/www/html --link wp-db:mysql -e WORDPRESS_DB_HOST=wp-db:3306 -e WORDPRESS_DB_PASSWORD=1234 -p 80:80 wordpress . http://localhost:8080 또는 http://localhost:8080/wp-admin/install.php로 확인 . .",
            "url": "https://nueees.github.io/techblog/kubernetes/2021/09/01/docker-container-configuration-management.html",
            "relUrl": "/kubernetes/2021/09/01/docker-container-configuration-management.html",
            "date": " • Sep 1, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "AWS EC2(Elastic Compute Cloud)",
            "content": "Coding Everybody . . 1.1. EC2 . 독립된 컴퓨터를 임대해주는 서비스 컴퓨터 1대 = Instance 1개 launch instance - 컴퓨터 생성 . 1.2. EC2 Instance Type . Amazon Machine Image (AMI) . OS : Linux(Ubuntu…), Window, … . Hardware spec . type (nano &lt; micro &lt; small &lt; medium &lt; large &lt; xlarge) : processor(vCPUs), Memory, Storage, Network Performance 우위에 따라 앞에 prefix가 다르게 붙음 | . 1.3. EC2 Instance Configuration . Configure Instance Detail . 1) Number of Instances: 만들 인스턴스 개수 2) Purchasing option: 요금제 선택 3) Network: VPC(AWS 계정 전용 가상 네트워크) 설정 4) Shutdown behavior: 컴퓨터 껐을 때 인스턴스를 어떻게 할 것인지 5) Enable termination protection : 인스턴스 삭제 시 보호 조치 6) Monitoring: CPU, Memory 사용률을 자세히 확인 시 . Add Storage . Size: size 설정 (default 8GB) Volume Type: SSD… IOPS: 저장 속도 Delete on Termination: 컴퓨터 폐기시 저장장치 폐기할지 (내장하드, 외장하드) . Tag Instance . Key: 이름 Value: Web server . Configure Security Group . 방화벽같은 기능 .",
            "url": "https://nueees.github.io/techblog/cloud/aws/ec2/2021/02/04/aws-ec2.html",
            "relUrl": "/cloud/aws/ec2/2021/02/04/aws-ec2.html",
            "date": " • Feb 4, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Apache Spark",
            "content": "📎 Tacademy . . 3.1. Spark . Unified Computing Engine and a Set of Libraries for Parallel Data Processing on Computer Clusters 용도: Machine learning, real time analytics, graph processing, etc. . Structured Streaming, Advanced Analytics, Libraries &amp; Ecosystem | High level APIs (Java, Python, …) | Low level APIs (RDDs, Distributed Variables) | Structured APIs (Datasets, DataFrames, SQL) | . 기존 MapReduce에서 disk I/O 부하가 심했던 부분을 memory에서 빠르게 작업 . 1) Low level APIs 직접 map와 reduce를 function으로 구현하여야 함 . 2) High level APIs (functional language) scala와 python으로 간단하게 처리 가능 (추상화되어 있음) . . 3.2. Spark Architecture . . executor 개수와 resource 할당 . Cluster Manager . worker와 executors 사이에 자원을 중계해주는 역할 resource를 효율적으로 분배 . ex) Spark StandAlone(cluster X), (Hadoop)Yarn, Mesos, Kubernetes . Driver Process . SparkContext를 생성하고 RDD를 만들고 operation을 실행하는 프로세스 . Spark-submit을 하면, Spark Driver가 Cluster Manager로부터 Executor 실행을 위한 리소스를 요청 Spark Context는 작업 내용을 task 단위로 분할하여 Executor로 보냄 . Executors . 주어진 작업의 개별 task들을 실행하는 작업 실행하고 결과 return . 1) 애플리케이션을 구성하는 작업들을 실행하여 driver에 그 결과를 return 2) 각 executor 안에 존재하는 block manager라는 서비스를 통해 사용자 프로그램에서 캐시하는 RDD를 저장하기 위한 메모리 저장소를 제공 . Python,R Process &lt;-&gt; JVM(Spark session) -&gt; Executors . End to End: csv file read(narrow) -&gt; DataFrame sort(wide) -&gt; Array . Operations . 1) Transformations: map, filter, groupBy, join lazy operation으로 즉시 실행하는 단계가 아님 . 2) Actions: count, collect, save 실제로 실행후 driver로 결과 return . . 3.3. Processing 방식 . Batch Processing . big &amp; complex | processing massive data | higher latencies | . Real-time Processing (Stream) . relatively simple and generally independent | one at a time processing | sub-second latency | . input data stream -&gt; spark streaming -&gt; batch input data -&gt; spark engine -&gt; processed batch data . spark streaming의 경우 개발하기는 어렵지 않으나, 운영(debugging)이 어려움 . . 3.4. Variables . Accumulator . aggregate multiple values as it progresses . Broadcast . large read-only variable shared across tasks, operations large lookup tables . 디버깅이나 검증용으로 쓰고 스파크 스트리밍에서는 accumulator, broadcast 지양 (GC문제..) . Fault Tolerance 비즈니스 요건에 따라, 실패시 누락이 되면 되는지 안되는지에 따라 고려 (Kafka) . . 3.5. Interface . RDDs (Resilient Distributed Datasets) . low level interface, Data Containers 각기 다른 프로세스 요소들을 추상화한 같은 형태 . 1) Hadoop에서 읽은 RDD path = hdfs://… . 2) Filtered된 RDD func = contains(…) . 3) Mapped된 RDD func = split(…) . Fault되면 Loss된 데이터 이전부터 다시 계산 . data = sc.textFile(...).split(&quot; t&quot;) data.map(lambda x: (x[0], [int(x[1]), 1])) .reduceByKey(lambda x, y: [x[0] + y[0], x[1] + y[1]]) .map(lambda x: [x[0], x[1][0] / x[1][1]]) .collect() . DataFrames . 코드가 직관적이고 schema를 가지는 interface . sqlCtx.table(&quot;people&quot;).groupBy(&quot;name&quot;).agg(&quot;name&quot;, avg(&quot;age&quot;)).collect() . . 3.6. Scheduling . . DAG (Directed Acyclic Graphs) Scheduler .",
            "url": "https://nueees.github.io/techblog/spark/etl/2021/02/03/apache-spark.html",
            "relUrl": "/spark/etl/2021/02/03/apache-spark.html",
            "date": " • Feb 3, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Apache Hadoop",
            "content": "📎 Tacademy . . 2.1. Hadoop . 대용량 데이터를 처리하기 위한 컴퓨터 클러스터에서 동작하는 분산 프로그램 (단일 서버 &lt; 클러스터로 묶은 서버) | 기존 RDBMS는 확장을 하려면 서버를 추가 구매해야하나 (scale-up) | Hadoop은 node(컴퓨터)를 추가함으로써 선형적으로 확장 가능 (scale-out) | . ### 저장 storage: HDFS(Hadoop Distributed File System) ### 연산: MapReduce . 파일을 block(64M,128M) 단위로 분할 | block들은 서로 다른 machine에 분산 저장(Mapreduce 처리) | block들은 여러 machine(기본 3 replication)에 복제되어 data node에 저장 | Master node인 name node는 meta data(저장된 위치, block의 file 정보 등) 관리 | . . 2.2. HDFS Access . 1) shell 2) java api 3) ecosystem - Flume(network source로 데이터 수집) - Sqoop(HDFS와 RDBMS 사이 데이터 전송) - Hue(Web 기반으로 browse, upload, download, file view) . file write &amp; read . name node의 mete data를 통해 접근 . 따라서 name node 데몬 중단되면 cluster 접근 불가 HA로 2개의 name node를 구성하기도 함 (Active/Standby) 1개 name node 구성시 helper node(Secondary name node)가 추가됨 . files blocks . /logs/031512.log | B1,B2,B3 | . /logs/041213.log | B4,B5 | . nodes   . node A | B1, B3, B4 | . node B | B1, B2, B3, B4 | . node C | B3, B5 | . node D | B1, B5, B2 | . node E | B2, B5, B4 | . node 중 idle이 높은 node부터 접근 . . 2.3. 구성요소 . 1) client node node를 통해 정보를 받고 이후 data node와 직접 통신 . 2) master node(job tracker, name node) slave node에 대한 정보와 실행할 task 관리 . 3) slave node(data node, task node) client 요청 시 data 전달, task 수행 . . Data Analytics 관점 . Job tracker: task tracker가 수행할 task 스케줄링, 모니터링 | Task tracker: task를 수행하고 job tracker에게 상황 | . Data Storage 관점 . Name node: Meta data 유지, client로 부터 데이터 요청오면 위치 전달 | Data node: 데이터를 HDFS block 단위로 구성, HA를 위한 replication 3 유지, heartbeat를 통한 파일 위치 전달 | . . 2.4. MapReduce . File . Deer, Bear, River | . Car, Car, River | . Deer, Car, Bear | . Mapping: 파일은 한 줄씩 읽어서 데이터 변경 . 데이터를 key와 value 형태로 pairing하고 list화 .     . map1 | Deer, 1 | .   | Bear, 1 | .   | River, 1 | . map2 | Car, 1 | .   | Car, 1 | .   | River, 1 | . map3 | Deer, 1 | .   | Car, 1 | .   | Bear, 1 | . shuffling . grouping, sorting .   . Bear, 1 | . Bear, 1 | . Car, 1 | . Car, 1 | . Car, 1 | . Deer, 1 | . Deer, 1 | . River, 1 | . River, 1 | . Reducing: map의 결과 데이터를 집계 . aggregating, 후 extract .     . red1 | Bear, 2 | . red2 | Car, 3 | . red3 | Deer, 2 | . red4 | River, 2 | .",
            "url": "https://nueees.github.io/techblog/hadoop/filesystem/2021/02/02/apache-hadoop.html",
            "relUrl": "/hadoop/filesystem/2021/02/02/apache-hadoop.html",
            "date": " • Feb 2, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Apache Kafka",
            "content": "📎 Tacademy . . 1.1. Kafka . a distributed, partitioned, and replicated commit log service . 소스 애플리케이션(mysql, oracle, nosql,…/app/was/…)과 타겟 애플리케이션(hadoop, search engine, monitoring, email…)개수가 많아지고,프로토콜 포맷 파편화가 심해져 유지보수가 어려워짐 . 이러한 복잡함을 해결하기 위해 중간에서 소스 애플리케이션과 타겟 애플리케이션 연결을 느슨하게 함 (scale out) . 프로듀서가 큐에 적재하고 컨슈머가 가져가는 구조 . Kafka Client: kafka와 데이터를 주고 받기 위해 사용하는 (producer, consumer, admin, stream 등) API | . . 1.2. Brocker &amp; Cluster . brocker: Kafka application 서버 단위 | cluster: 3대 이상의 brocker로 구성 . | zookeeper: metadata 저장하여 brockers 관리 | controller: n대 brocker 중 마스터 brocker (allocate partition, health check) | . . 1.3. Topic . 메시지(데이터) 분류 단위 n개의 파티션 할당 가능 각 파티션 마다 고유 offset 가짐 메시지 처리순서는 파티션 별로 관리 . partition: 레코드를 담고 있고 replication 가능 | ISR(In-Sync Replica): replication(leader+follower)의 sync로 된 묶음 | segment: 실제로 메시지가 저장되는 파일 시스템 단위 | . . 1.4. Producer . 메시지(레코드)를 brocker로 송신 API . Role . Topic에 해당하는 메시지를 해당 파티션에 offset과 함께 기록 . Publishing: 특정 topic으로 데이터 송신 | 처리 실패 시 재시도 | key 사용시, 해당 partition으로 데이터 매핑 | . . 1.5. Consumer . 메시지(레코드) brocker에서 수신 API 다수의 consumer를 group화 할 수 있음 . Role . Polling: Topic의 partition으로 부터 메시지(레코드)를 가져감 | Commit: Partition offset 위치를 기록 | Parallel Processing: Consumer 여러개일 경우, Consumer group을 통해 병렬 처리 | . Offset number: . 파티션 내 갖게되는 고유 키 토픽 별, 파티션 별로 고유하게 지정됨 컨슈머가 데이터를 어디까지 읽었는지 확인하는 용도 데이터를 읽은 곳까지 commit . 컨슈머 이슈가 발생해도 __consumer_offset 토픽에 저장된 지점 확인(High availablility) . . 병렬처리를 위해서는 consumer 개수는 partition 개수보다 적거나 같아야 함 . . 1.6. Kafka Streams . 데이터 변환(transformation) API . stateful, stateless와 같은 상태 기반 stream 처리 가능 | stream api와 DSL(Domain Specific Language) 동시 지원 | Exactly-once 처리, HA 특징 | Kafka security(acl, sasl 등) 지원 | stream 처리를 위한 별도 cluster(yarn 등) 불필요 | . . 1.7. Kafka Connect . Kafka client가 아닌 connect를 통해 데이터를 import/export 가능 code 없이 configuration으로 데이터 migration 시 사용 .",
            "url": "https://nueees.github.io/techblog/kafka/message_broker/queue/2021/02/01/apache-kafka.html",
            "relUrl": "/kafka/message_broker/queue/2021/02/01/apache-kafka.html",
            "date": " • Feb 1, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "Sequence of characters",
            "content": "Python Algorithm Practice . . 3.1. Sequence of characters . N개의 문자열 데이터를 입력받아 앞에서 읽을 때나 뒤에서 읽을 때나 같은 경우(회문 문자열)이면 YES를 출력하고 회문 문자열이 아니면 NO를 출력하는 프로그램을 작성한다. 단 회문을 검사할 때 대소문자를 구분하지 않습니다. . n = int(input()) for i in range(n): s = input() s = s.lower() size = len(s) for j in range(size//2): if s[j] != s[-1-j]: print(f&quot;#{i+1} NO&quot;) break else: print(f&quot;#{i+1} YES&quot;) # s[::-1]으로도 구현 가능함. . . 3.2. Extract only number . 문자와 숫자가 섞여있는 문자열이 주어지면 그 중 숫자만 추출하여 그 순서대로 자연수를 만듭니다. 만들어진 자연수와 그 자연수의 약수 개수를 출력합니다. 만약 “t0e0a1c2h0er”에서 숫자만 추출하면 0, 0, 1, 2, 0이고 이것을 자연수를 만들면 120이 됩니다. 즉 첫자리 0은 자연수화 할 때 무시합니다. 출력은 120를 출력하고, 다음 줄에 120의 약수의 개수를 출력하면 됩니다. 추출하여 만들어지는 자연수는 100,000,000을 넘지 않습니다. . s = input() res = 0 for i in s: if i.isdigit(): res = res*10 + int(i) cnt = 0 for i in range(1,res+1): if res%i==0: cnt += 1 print(cnt) . . 3.3. Reverse cards . 1부터 20까지 숫자가 하나씩 쓰인 20장의 카드가 아래 그림과 같이 오름차순으로 한 줄로 놓여있다. 각 카드의 위치는 카드 위에 적힌 숫자와 같이 1부터 20까지로 나타낸다. . |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20| |:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:|:–:| . 이제 여러분은 다음과 같은 규칙으로 카드의 위치를 바꾼다: 구간 [a, b] (단, 1 ≤ a ≤ b ≤ 20)가 주어지면 위치 a부터 위치 b까지의 카드를 현재의 역순으로 놓는다. 예를 들어, 현재 카드가 놓인 순서가 위의 그림과 같고 구간이 [5, 10]으로 주어진다면, 위치 5부터 위치 10까지의 카드 5, 6, 7, 8, 9, 10을 역순으로 하여 10, 9, 8, 7, 6, 5로 놓는다. 이제 전체 카드가 놓인 순서는 아래 그림과 같다. . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 . 1 | 2 | 3 | 4 | 10 | 9 | 8 | 7 | 6 | 5 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | . 이 상태에서 구간 [9, 13]이 다시 주어진다면, 위치 9부터 위치 13까지의 카드 6, 5, 11, 12, 13을 역순으로 하여 13, 12, 11, 5, 6으로 놓는다. 이제 전체 카드가 놓인 순서는 아래 그림과 같다. . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 . 1 | 2 | 3 | 4 | 10 | 9 | 8 | 7 | 6 | 5 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | . 1 | 2 | 3 | 4 | 10 | 9 | 8 | 7 | 13 | 12 | 11 | 5 | 6 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | . 오름차순으로 한 줄로 놓여있는 20장의 카드에 대해 10개의 구간이 주어지면, 주어진 구간의 순서대로 위의 규칙에 따라 순서를 뒤집는 작업을 연속해서 처리한 뒤 마지막 카드들의 배치를 구하는 프로그램을 작성하세요. . a = list(range(0,21)) for _ in range(10): s, e = map(int, input().split()) for i in range((e-s+1)//2): a[s+i], a[e-i] = a[e-i], a[s+i] a.pop(0) print(a) ## 또는 s,e 받고 난 후 역배열 바꿔서 해도 됨 아래 참조 tmp = a[s-1:e] a[s-1:e] = tmp[::-1] . . 3.4. Merge lists . 오름차순으로 정렬이 된 두 리스트가 주어지면 두 리스트를 오름차순으로 합쳐 출력하는 프로그램을 작성하세요. . # sort로 바로 구할 수도 있지만 포인터 연습으로 구현 n1 = int(input()) l1 = list(map(int, input().split())) n2 = int(input()) l2 = list(map(int, input().split())) p1=p2=0 res = [] while p1&lt;n1 and p2&lt;n2: if l1[p1] &lt;= l2[p2]: res.append(l1[p1]) p1 += 1 else: res.append(l2[p2]) p2 += 1 if p1&lt;n1: res = res + l1[p1:] if p2&lt;n2: res = res + l2[p2:] for i in res: print(i, end=&#39; &#39;) . . 3.5. Sum of Numbers . N개의 수로 된 수열 $A[1], A[2], …, A[N]$ 이 있다. 이 수열의 i번째 수부터 j번째 수까지의 합 $A[i]+A[i+1]+…+A[j-1]+A[j]$가 M이 되는 경우의 수를 구하는 프로그램을 작성하시오. . n, m = map(int, input().split()) a = list(map(int,input().split())) cnt = 0 for i in range(n): for j in range(i+1,n): if m==sum(a[i:j+1]): cnt += 1 print(cnt) ## 다른 방법 lt = 0 rt = 1 tot = a[0] cnt = 0 while True: if tot &lt; m: if rt &lt; n: tot += a[rt] else: break elif tot == m: cnt += 1 tot -= a[lt] lt += 1 else: tot -= a[lt] lt += 1 . . 3.6. Sum of Matrix . 5*5 격자판에 아래와 같이 숫자가 적혀있습니다. .           . 10 | 13 | 10 | 12 | 15 | . 12 | 39 | 30 | 28 | 11 | . 11 | 25 | 50 | 53 | 15 | . 19 | 27 | 29 | 37 | 27 | . 19 | 13 | 30 | 13 | 19 | . N*N의 격자판이 주어지면 각 행의 합, 각 열의 합, 두 대각선의 합 중 가 장 큰 합을 출력합니다. . n = int(input()) mat = [list(map(int, input().split())) for _ in range(n)] max = 0 mrow = 0 mcol = 0 for i in range(n): mrow = mcol = 0 for j in range(n): mrow += mat[i][j] mcol += mat[j][i] if mrow &gt; max: max = mrow if mcol &gt; max: max = mcol rdiag = 0 ldiag = 0 for i in range(n): # diagonal rdiag += mat[i][i] # right diagonal ldiag += mat[i][n-i-1] # left diagonal if rdiag &gt; max: max = rdiag if ldiag &gt; max: max = ldiag print(max) . . 3.7. Diamond . 현수의 농장은 N*N 격자판으로 이루어져 있으며, 각 격자안에는 한 그루의 사과나무가 심어져있다. N의 크기는 항상 홀수이다. 가을이 되어 사과를 수확해야 하는데 현수는 격자판안의 사과를 수확할 때 다이아몬드 모양의 격자판만 수확하고 나머지 격자안의 사과는 새들을 위해서 남겨놓는다. 만약 N이 5이면 아래 그림과 같이 진한 부분의 사과를 수확한다. .           . 10 | 13 | 10 | 12 | 15 | . 12 | 39 | 30 | 28 | 11 | . 11 | 25 | 50 | 53 | 15 | . 19 | 27 | 29 | 37 | 27 | . 19 | 13 | 30 | 13 | 19 | . 현수과 수확하는 사과의 총 개수를 출력하세요. . n = int(input()) mat = [list(map(int, input().split())) for _ in range(n)] res = 0 s = e = n//2 for i in range(n): for j in range(s, e+1): res += mat[i][j] if i &lt; n//2: s -= 1 e += 1 else: s += 1 e -= 1 print(res) . . 3.8. Sandglass . 현수는 곳감을 만들기 위해 감을 깍아 마당에 말리고 있습니다. 현수의 마당은 N*N 격자판으로 이루어져 있으며, 현수는 각 격자단위로 말리는 감의 수를 정합니다. 그런데 해의 위치에 따라 특정위치의 감은 잘 마르지 않습니다. 그래서 현수는 격자의 행을 기준으로 왼쪽, 또는 오른쪽으로 회전시켜 위치를 변경해 모든 감이 잘 마르게 합니다. 만약 회전명령 정보가 2 0 3이면 2번째 행을 왼쪽으로 3만큼 아래 그림처럼 회전시키는 명령입니다. .           . 10 | 13 | 10 | 12 | 15 | . 12 | 39 | 30 | 28 | 11 | . 11 | 25 | 50 | 53 | 15 | . 19 | 27 | 29 | 37 | 27 | . 19 | 13 | 30 | 13 | 19 | .           . 10 | 13 | 10 | 12 | 15 | . 23 | 11 | 12 | 39 | 30 | . 11 | 25 | 50 | 53 | 15 | . 19 | 27 | 29 | 37 | 27 | . 19 | 13 | 30 | 13 | 19 | . 첫 번째 수는 행번호, 두 번째 수는 방향인데 0이면 왼쪽, 1이면 오른쪽이고, 세 번째 수는 회전하는 격자의 수입니다. M개의 회전명령을 실행하고 난 후 아래와 같이 마당의 모래시계 모양의 영역에는 감 이 총 몇 개가 있는지 출력하는 프로그램을 작성하세요. .           . 10 | 13 | 10 | 12 | 15 | . 23 | 11 | 12 | 39 | 30 | . 11 | 25 | 50 | 53 | 15 | . 19 | 27 | 29 | 37 | 27 | . 19 | 13 | 30 | 13 | 19 | . n = int(input()) mat = [list(map(int,input().split())) for _ in range(n)] m = int(input()) for _ in range(m): row, tw, k = map(int,input().split()) if tw == 0: # toward left mat[row-1] = mat[row-1][k:]+mat[row-1][:k] else: # toword right mat[row-1] = mat[row-1][-k:]+mat[row-1][:-k] s = 0 e = n res = 0 for i in range(n): res += sum(mat[i][s:e]) # print(mat[i][s:e]) if i &lt; n//2: s += 1 e -= 1 else: s -= 1 e += 1 print(res) . . 3.9. Hill . 지도 정보가 N*N 격자판에 주어집니다. 각 격자에는 그 지역의 높이가 쓰여있습니다. 각 격자판의 숫자 중 자신의 상하좌우 숫자보다 큰 숫자는 봉우리 지역입니다. 봉우리 지역이 몇 개 있는 지 알아내는 프로그램을 작성하세요. 격자의 가장자리는 0으로 초기화 되었다고 가정한다. 만약 N=5 이고, 격자판의 숫자가 다음과 같다면 봉우리의 개수는 10개입니다. .               . 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 0 | 5 | 3 | 7 | 2 | 3 | 0 | . 0 | 3 | 7 | 1 | 6 | 1 | 0 | . 0 | 7 | 2 | 5 | 3 | 4 | 0 | . 0 | 4 | 3 | 6 | 4 | 1 | 0 | . 0 | 8 | 7 | 3 | 5 | 2 | 0 | . 0 | 0 | 0 | 0 | 0 | 0 | 0 | . n = int(input()) mat = [list(map(int,input().split())) for _ in range(n)] mat.insert(0, [0]*n) # upper padding mat.append([0]*n) # lower padding for i in mat: i.insert(0, 0) # left padding i.append(0) # right padding dx = [-1, 0, 1, 0] # direction x dy = [0, 1, 0, -1] # direction y cnt = 0 for i in range(1, n+1): for j in range(1, n+1): if all(mat[i][j] &gt; mat[i+dx[k]][j+dy[k]] for k in range(4)): cnt += 1 print(cnt) . . 3.10. Sudoku . 스도쿠는 매우 간단한 숫자 퍼즐이다. 9×9 크기의 보드가 있을 때, 각 행과 각 열, 그리고 9개의 3×3 크기의 보드에 1부터 9까지의 숫자가 중복 없이 나타나도록 보드를 채우면 된다. 예를 들어 다음을 보자. .                   . 1 | 4 | 3 | 6 | 2 | 8 | 5 | 7 | 9 | . 5 | 7 | 2 | 1 | 3 | 9 | 4 | 6 | 8 | . 9 | 8 | 6 | 7 | 5 | 4 | 2 | 3 | 1 | . 3 | 9 | 1 | 5 | 4 | 2 | 7 | 8 | 6 | . 4 | 6 | 8 | 9 | 1 | 7 | 3 | 5 | 2 | . 7 | 2 | 5 | 8 | 6 | 3 | 9 | 1 | 4 | . 2 | 3 | 7 | 4 | 8 | 1 | 6 | 9 | 5 | . 6 | 1 | 9 | 2 | 7 | 5 | 8 | 4 | 3 | . 8 | 5 | 4 | 3 | 9 | 6 | 1 | 2 | 7 | . 위 그림은 스도쿠를 정확하게 푼 경우이다. 각 행에 1부터 9까지의 숫자가 중복 없이 나오고, 각 열에 1부터 9까지의 숫자가 중복 없이 나오고, 각 3×3짜리 사각형(9개이며, 예시로 위에서 굵은 숫자)에 1부터 9까지의 숫자가 중복 없이 나오기 때문이다. 완성된 9×9 크기의 수도쿠가 주어지면 정확하게 풀었으면 “YES”, 잘 못 풀었으면 “NO”를 출력하는 프로그램을 작성하세요. . mat = [list(map(int,input().split())) for _ in range(9)] def check(mat): for i in range(9): chk1 = [0]*10 # row check chk2 = [0]*10 # col check for j in range(9): chk1[mat[i][j]] = 1 chk2[mat[j][i]] = 1 if sum(chk1) != 9 or sum(chk2) != 9: return False for i in range(3): # outer for j in range(3): chk3 = [0]*10 # 3x3 group check for i2 in range(3): # inner for j2 in range(3): chk3[mat[i*3+i2][j*3+j2]] = 1 if sum(chk3) != 9: return False return True if check(mat): print(&quot;YES&quot;) else: print(&quot;NO&quot;) . . 3.11. Mirrored String in Matrix . 1부터 9까지의 자연수로 채워진 7*7 격자판이 주어지면 격자판 위에서 가로방향 또는 세로방향으로 길이 5자리 회문수가 몇 개 있는지 구하는 프로그램을 작성하세요. 회문수란 121과 같이 앞에서부터 읽으나 뒤에서부터 읽으나 같은 수를 말합니다. . . 빨간색처럼 구부러진 경우(87178)는 회문수로 간주하지 않습니다. . sys.stdin=open(&quot;input.txt&quot;, &quot;r&quot;) mat = [list(map(int, input().split())) for _ in range(7)] cnt=0 for i in range(3): for j in range(7): tmp = mat[j][i:i+5] if tmp == tmp[::-1]: cnt+=1 for k in range(2): if mat[i+k][j] != mat[i+5-k-1][j]: break else: cnt+=1 print(cnt) . .",
            "url": "https://nueees.github.io/techblog/algorithm/python/2020/12/02/sequence-of-characters.html",
            "relUrl": "/algorithm/python/2020/12/02/sequence-of-characters.html",
            "date": " • Dec 2, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Nth Prime Number",
            "content": "Python Algorithm Practice . . 2.1. Nth Prime Number . 두 개의 자연수 N과 K가 주어졌을 때, N의 약수들 중 K번째로 작은 수를 출력하는 프로그램을 작성하세요. . n, k = map(int, input().split()) print(n,k) cnt = 0 for i in range(1,n+1): if n%i==0: cnt+=1 if cnt==k: print(i) break else: print(-1) . . 2.2. Nth Number . N개의 숫자로 이루어진 숫자열이 주어지면 해당 숫자열중에서 s번째부터 e번째까지의 수를 오름차순 정렬했을 때 k번째로 나타나는 숫자를 출력하는 프로그램을 작성하세요. . T = int(input()) for i in range(T): n, s, e, k = map(int, input().split()) a = list(map(int, input().split())) # print(n,s,e,k) cnt = 0 a = a[s-1:e] a.sort() print(a[k-1]) . . 2.3. Nth Biggest Number . 1부터 100사이의 자연수가 적힌 N장의 카드를 가지고 있습니다. 같은 숫자의 카드가 여러장 있을 수 있습니다. 이 중 3장을 뽑아 각 카드에 적힌 수를 합한 값을 기록하려고 합니다. 3장을 뽑을 수 있는 모든 경우를 기록합니다. 기록한 값 중 K번째로 큰 수를 출력하는 프로그램을 작성하세요. . n, k = map(int, input().split()) a = list(map(int, input().split())) myset = set() # to remove duplication for i in range(n): for j in range(i+1, n): for l in range(j+1): myset.add(a[i]+a[j]+a[l]) res = list(myset) res.sort(reverse=True) print(res[k-1]) . . 2.4. Closest Representative value . N명의 학생의 수학점수가 주어집니다. N명의 학생들의 평균(소수 첫째자리 반올림)을 구하고, N명의 학생 중 평균에 가장 가까운 학생은 몇 번째 학생인지 출력하는 프로그램을 작성하세요. 평균과 가장 가까운 점수가 여러 개일 경우 먼저 점수가 높은 학생의 번호를 답으로 하고, 높은 점수를 가진 학생이 여러 명일 경우 그 중 학생번호가 빠른 학생의 번호를 답으로 합니다. . n = int(input()) a = list(map(int, input().split())) avg = round(sum(a)/n) min = 2**10000 for idx, x in enumerate(a): tmp = abs(x-avg) if tmp &lt; min: min = tmp score = x res = idx+1 elif tmp == min: if x &gt; score: score = x res = idx+1 print(avg, res) . . 2.5. Regular Polyhedron . 두 개의 정 N면체와 정 M면체의 두 개의 주사위를 던져서 나올 수 있는 눈의 합 중 가장 확률이 높은 숫자를 출력하는 프로그램을 작성하세요. 정답이 여러 개일 경우 오름차순으로 출력합니다. . n, m = map(int, input().split()) cnt = [0]*(n+m+1) cnt for i in range(1, n+1): for j in range(1, m+1): cnt[i+j] += 1 cnt max = -1 for i in range(1,len(cnt)): if cnt[i]&gt;max: max=cnt[i] for i in range(1,len(cnt)): if cnt[i]==max: print(i, end=&#39; &#39;) . . 2.6. Sum the Digits of a Number . N개의 자연수가 입력되면 각 자연수의 자릿수의 합을 구하고, 그 합이 최대인 자연수를 출력하는 프로그램을 작성하세요. . n = int(input()) a = list(map(int, input().split())) def digit_sum(x): sum = 0 while x&gt;0: sum += x%10 x = x//10 return sum max = 0 for x in a: tot = digit_sum(x) if tot &gt; max: max = tot res = x print(res) . . 2.7. Prime Number . 자연수 N이 입력되면 1부터 N까지의 소수의 개수를 출력하는 프로그램을 작성하세요. 예를 들어 20이 입력되면 1부터 20까지의 소수는 2, 3, 5, 7, 11, 13, 17, 19로 총 8개입니다. (제한시간은 1초) . n = int(input()) plist = [0]*(n+1) cnt = 0 for i in range(2,n+1): if plist[i] == 0: cnt += 1 for j in range(i,n+1,i): plist[j] = 1 print(cnt) . . 2.8. Prime with digits reversed . N개의 자연수가 입력되면 각 자연수를 뒤집은 후 그 뒤집은 수가 소수이면 그 수를 출력하는 프로그램을 작성하세요. 예를 들어 32를 뒤집으면 23이고, 23은 소수이다. 그러면 23을 출력한다. 단 910를 뒤집으면 19로 숫자화 해야 한다. 첫 자리부터의 연속된 0은 무시한다. . n = int(input()) a = list(map(int, input().split())) def reverse(x): res = 0 while x&gt;0: t = x%10 res = res*10+t x = x//10 return res def isPrime(x): if x==1: return False for i in range(2,x//2+1): if x%i==0: return False else: return True for x in a: tmp = reverse(x) if isPrime(tmp): print(tmp, end=&#39; &#39;) . . 2.9. Dice game . 1에서부터 6까지의 눈을 가진 3개의 주사위를 던져서 다음과 같은 규칙에 따라 상금을 받는 게임이 있다. 규칙(1) 같은 눈이 3개가 나오면 10,000원+(같은 눈)*1,000원의 상금을 받게 된다. 규칙(2) 같은 눈이 2개만 나오는 경우에는 1,000원+(같은 눈)*100원의 상금을 받게 된다. 규칙(3) 모두 다른 눈이 나오는 경우에는 (그 중 가장 큰 눈)*100원의 상금을 받게 된다. 예를 들어, 3개의 눈 3, 3, 6이 주어지면 상금은 1,000+3*100으로 계산되어 1,300원을 받게 된다. 또 3개의 눈이 2, 2, 2로 주어지면 10,000+2*1,000 으로 계산되어 12,000원을 받게 된다. 3개의 눈이 6, 2, 5로 주어지면 그 중 가장 큰 값이 6이므로 6*100으로 계산되어 600원을 상금으로 받게 된다. N 명이 주사위 게임에 참여하였을 때, 가장 많은 상금을 받은 사람의 상금을 출력하는 프로그램을 작성하세요. . n = int(input()) sum = 0 for i in range(n): tmp = input().split() tmp.sort(reverse=True) a,b,c = map(int, tmp) if a==b and a==c: sum += 10000 + (a * 1000) elif a==b: sum += 1000 + (a * 100) elif b==c: sum += 1000 + (b * 100) else: sum += (a * 100) print(sum) . . 2.10. Calculate a score . OX 문제는 맞거나 틀린 두 경우의 답을 가지는 문제를 말한다. 여러 개의 OX 문제로 만들어진 시험에서 연속적으로 답을 맞히는 경우에는 가산점을 주기 위해서 다음과 같이 점수 계산을 하기로 하였다. 1번 문제가 맞는 경우에는 1점으로 계산한다. 앞의 문제에 대해서는 답을 틀리다가 답이 맞는 처음 문제는 1점으로 계산한다. 또한, 연속으로 문제의 답이 맞는 경우에서 두 번째 문제는 2점, 세 번째 문제는 3점, …, K번째 문제는 K점으로 계산한다. 틀린 문제는 0점으로 계산한다. 예를 들어, 아래와 같이 10 개의 OX 문제에서 답이 맞은 문제의 경우에는 1로 표시하고, 틀린 경우에는 0으로 표시하였을 때, 점수 계산은 아래 표와 같이 계산되어, 총 점수는 1+1+2+3+1+2=10 점이다. . 채점 1 0 1 1 1 0 0 1 1 0 . 점수 | 1 | 0 | 1 | 2 | 3 | 0 | 0 | 1 | 2 | 0 | . 시험문제의 채점 결과가 주어졌을 때, 총 점수를 계산하는 프로그램을 작성하세요. . n = int(input()) a = list(map(int, input().split())) sum = 0 cnt = 0 for x in a: if x == 1: cnt += 1 sum += cnt else: cnt = 0 print(sum) . .",
            "url": "https://nueees.github.io/techblog/algorithm/python/2020/12/01/nth-prime-number.html",
            "relUrl": "/algorithm/python/2020/12/01/nth-prime-number.html",
            "date": " • Dec 1, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "추정",
            "content": "R과 함께하는 통계학의 이해 - 최용석 . . 6.1 통계적 추론 . 통계적 추론(statistical inference): 모집단의 수치적 특성을 나타내는 모수(parameter)에 대한 정보를 얻어내기 위한 일련의 과정 . 통계량(statistic)들의 값을 계산하고 이것을 이용하여 모집단의 특성(모수)를 알아보는 것이다. . 1) 추정(estimation): 모수에 대한 추측값을 얻되, 그 값의 정밀도를 함께 구하는 것 . 2) 가설 검정(hypotheses testing): 표본의 자료가 모수의 참값에 대한 조사자의 추측을 뒷받침하는지 혹은 반증하는지 결정하는 것 -&gt; 7장 . . 6.2 모평균에 대한 점추정 . 점추정: 모수의 참값과 유사할 것이라고 예상되는 하나의 값 제시 . 모집단의 크기가 $n$인 표본을 임의로 추출할 때 이를 $n$개의 확률변수 $X_1,X_2,…,X_n$으로 표현 추정하고자 하는 하나의 모수에 대하여 이들 $n$개의 확률변수를 이용하여 하나의 통계량을 만들고, 나아가 주어진 표본으로부터 그 실제값을 계산하여 하나의 수치를 제시하는 것 . 추정량(estimator): 모수를 추정하기 위해 만들어진 통계량 (ex. $ hat{ mu}, hat{ sigma} $) . 추정치(estimate): 주어진 표본으로부터 계산된 추정량의 실제값 . $ hat{ mu} = bar{X} = frac{1}{n}(X_1+X_2+…+X_n) = frac{1}{n} sum{X_i}$ . 여기서 $ hat{ mu}$는 모평균 $ mu$에 대한 추정량 . 이러한 추정량은 확률변수들로부터 만들어진 하나의 확률변수이므로 추출된 표본의 값에 따라 그 값(추정치)가 달라질 수 있다. . 표준오차(standard error, S.E.): 수치(추정치)들의 변동은 추정량의 정확도와 관계가 있는데, 이 정확도를 측정하기 위해 추정량의 표준편차를 계산한 것 . $ E( bar{X}) = mu , quad S.E.( bar{X}) = frac{ sigma}{ sqrt{n}} $ 따라서 표본평균 $ bar{X} $를 이용하여 모평균 $ mu$를 추정하고자 할 경우 표본의 크기 $n$이 클수록 표준오차가 작아져서 보다 정확한 추정이 가능하다. 하지만 모수인 $ sigma $(모집단의 표준편차)를 모르는 경우 계산할 수 없다. 표본의 표준편차 $ hat{ sigma} $를 이용하여 추정할 수 있다. . $ hat{ sigma} = s = sqrt{ frac{1}{n-1} sum{(X_i- bar{X})^2} } $ . 소나무 성장 연구를 위한 1년생 소나무 묘목 40그루의 크기를 조사한 자료 : 2.6, 1.9, 1.8, 1.6, 1.4, 2.2,…,1.2 전체 1년생 소나무 묘목의 평균 크기에 대한 추정치(= 표본평균($ bar{x}$)) 와 표준오차($ frac{s}{ sqrt{n}}$) : $ bar{x} = frac{1}{40} times (2.6+1.9+…+1.2) = 1.715 $ $ s^2 = frac{1}{40-1} times { (2.6 - 1.715)^2 + … + (1.2-1.715)^2 } = 0.2254 $ $ frac{s}{ sqrt{n}} = frac{ sqrt{0.2254} } { sqrt{40}} = 0.0751 $ | . . 6.3 모평균에 대한 구간추정 . 구간추정: 모수의 참값을 포함할 것으로 예상되는 적절한 구간을 제시 . . 6.4 모비율에 대한 추정 . .",
            "url": "https://nueees.github.io/techblog/statistics/2019/09/04/%EC%B6%94%EC%A0%95.html",
            "relUrl": "/statistics/2019/09/04/%EC%B6%94%EC%A0%95.html",
            "date": " • Sep 4, 2019"
        }
        
    
  
    
        ,"post14": {
            "title": "표집분포와 중심극한정리",
            "content": "R과 함께하는 통계학의 이해 - 최용석 . . 5.1 표집분포 . 모수(parameter): 모집단에 대한 수치적 특성값 (모평균, 모비율, 모분산…) . 통계량(statistic): 표본으로부터 획득한 수치적 정보 . 통계량은 그 자체가 하나의 확률변수로서 확률분포를 가지게 된다. . 표집분포(sampling distribution): 통계량이 가지는 확률분포 . 표본 추출과정에서 발생하는 통계량의 값이 가지는 변동은 이 표집분포에 의해 설명될 수 있다. 표집분포는 모집단의 분포에 영향을 받기도 하고 표본의 크기 $n$에도 영향을 받는다. . 확률표본(random sample): 크기가 큰 모집단으로부터 임의 추출된 크기 $n$의 표본 $X_1,X_2,…,X_n$ . $X_1,X_2,…,X_n$은 서로 독립이고 모집단의 분포와 같은 분포를 가진다. . . 5.2 표본평균의 분포와 중심극한정리 . 크기가 $n$인 확률표본 $X_1,X_2,…,X_n$에 대해 $ E(X) = mu $, $ Var(X) = sigma^2 $, $i=1,2,…,n$이고, . $ bar{X} = frac{1}{n} sum{X_i} $일 때, . 표본평균 $ bar{X}$의 기대값과 분산 . $ E( bar{X}) = mu $ $ Var( bar{X}) = frac{ sigma^2}{n} $ . 정규모집단으로부터의 표본평균에 대한 확률분포 . 크기가 $n$인 확률표본 $X_1,X_2,…,X_n$에 대해 $ X_i sim N( mu, sigma^2) $, $i=1,2,…,n$일때, . 표본평균 $ bar{X}$의 확률분포는 $ bar{X} sim N( mu, frac{ sigma^2}{n}) $를 따르게 된다. . 중심극한정리 : 평균이 $ mu$이고 분산이 $ sigma^2$인 모집단으로부터 추출한 크기 $n$의 확률표본의 표본평균 $ bar{X}$는 표본의 크기가 큰 경우(보통 30 이상), 근사적으로 $ mu$이고 분산이 $ frac{ sigma^2}{n}$인 정규분포를 따르게 된다. . .",
            "url": "https://nueees.github.io/techblog/statistics/2019/09/03/%ED%91%9C%EC%A7%91%EB%B6%84%ED%8F%AC%EC%99%80-%EC%A4%91%EC%8B%AC%EA%B7%B9%ED%95%9C%EC%A0%95%EB%A6%AC.html",
            "relUrl": "/statistics/2019/09/03/%ED%91%9C%EC%A7%91%EB%B6%84%ED%8F%AC%EC%99%80-%EC%A4%91%EC%8B%AC%EA%B7%B9%ED%95%9C%EC%A0%95%EB%A6%AC.html",
            "date": " • Sep 3, 2019"
        }
        
    
  
    
        ,"post15": {
            "title": "연속확률변수 및 분포",
            "content": "R과 함께하는 통계학의 이해 - 최용석 . . 4.1 연속확률변수의 확률분포함수 . 연속확률변수: 확률변수가 특정 구간의 모든 값을 다 가질 수 있기 때문에 가질 수 있는 값들을 일일이 지칭할 수 없는 확률변수를 의미 . 연속확률분포함수: 확률변수 $X$가 가질 수 있는 특정 구간에서 확률이 어떻게 분포하는가를 나타낼 수 있는 함수 . $X$의 확률분포는 확률의 밀도를 나타내는 확률밀도함수 . 확률밀도함수(probability density function) . 모든 $x$에 대해 $f(x) geq 0 $ | $P(a leq X leq b) = int_{a}^{b}{f(x)dx}$ | $P( infty leq X leq - infty) = int_{ infty}^{- infty}{f(x)dx} = 1$ | . 연속확률변수 $X$가 특정한 값 $x$를 갖게 되는 확률은 0이므로, 구간의 확률을 구할 때는 그 구간의 경계점의 포함 유무는 영향을 받지 않는다. . 연속확률변수의 기대값과 분산 . $ E(X) = int{xf(x)dx} $ $ Var(X) = int{(x- mu)^2f(x)dx} = sigma^2 $ . . 4.2 정규분포 . 정규분포(normal distribution): 좌우대칭의 종모양 곡선 (=Gaussian distribution) . 정규확률변수 : 종 모양의 확률밀도함수를 가지는 연속형확률변수 X . 정규확률변수의 확률분포에 대한 식은 모집단에 대한 평균 $ mu$와 분산 $ sigma^2$에 의존하므로 $ X sim N( mu, sigma^2) $ 로 표기 . . 4.3 정규분포의 확률계산 . 표준정규분포(standard normal distribution): 평균이 0이고, 분산이 1인 정규분포 . 일반적으로 표준정규분포를 따르는 확률변수는 $Z$로 표현 $ Z sim N(0,1) $이므로 확률변수 $Z$는 평균 $E(Z) = mu_z = 0 $이며, 분산은 $ Var(Z) = sigma_z^2 = 1 $과 같다. . 일반적인 정규분포를 따르는 확률변수 $X$에 대한 확률을 표준정규분포를 따르는 확률변수 $Z$로 변환하는 과정을 표준화(Standardization)라고 한다. . $ frac{X- mu_x}{ sigma_x} $ . . 4.4 이항분포의 정규근사 . . $n$이 증가함에 따라 분포의 형태가 점차 좌우대칭의 종 모양에 가까워짐을 확인할 수 있다. . 이항분포의 정규근사 . 확률변수 $X$가 성공 횟수를 나타내는 이산형 확률변수이고 $X sim Bin(n,p) $일 때, $np$나 $n(1-p)$이 모두 충분히 클 경우(보통 10 이상)에 확률변수 $X$는 근사적으로 다음의 정규 분포를 따르게 된다. $ X sim N(np, np(1-p)) $ . .",
            "url": "https://nueees.github.io/techblog/statistics/2019/09/02/%EC%97%B0%EC%86%8D%ED%99%95%EB%A5%A0%EB%B3%80%EC%88%98-%EB%B0%8F-%EB%B6%84%ED%8F%AC.html",
            "relUrl": "/statistics/2019/09/02/%EC%97%B0%EC%86%8D%ED%99%95%EB%A5%A0%EB%B3%80%EC%88%98-%EB%B0%8F-%EB%B6%84%ED%8F%AC.html",
            "date": " • Sep 2, 2019"
        }
        
    
  
    
        ,"post16": {
            "title": "이산확률변수 및 분포",
            "content": "R과 함께하는 통계학의 이해 - 최용석 . . 3.1 사건의 확률 . 확률(probability) : 실험의 결과에 대해 확신하는 정도를 수치적으로 나타는 척도 . 사건(event) : 어떤 특성을 갖는 결과들의 집합을 ($A$, $B$, …) . P(A)=frac사건A에속하는결과수표본공간에속하는결과수P(A) = frac{사건A에 속하는결과 수}{표본공간에 속하는 결과 수}P(A)=frac사건A에속하는결과수표본공간에속하는결과수 . . 3.2. 확률변수 . 확률변수(random variable) : 표본공간에 속하는 각각의 결과들에 대해 실수값 대응 시켜준 변수 ($X$, $Y$, …) . 한주에 경기 수 (0회, 1회, 2회) | . 확률변수가 가지는 특정값 : ($x$, $y$, …) . 가질 수 있는 값에 따라, . 1) 이산확률변수(discrete random variable) 2) 연속확률변수(continuous random variable) . . 3.3 이산확률변수의 확률분포함수 . 확률분포(probability distribution) : 확률변수가 가지는 값과 그 값을 가질 확률을 정해주는 규칙 . 한주의 경기 수와 그 비율 (0회: $ frac{2}{10}$, 1회: $ frac{5}{10}$, 2회: $ frac{3}{10}$) | . (이산확률변수의) 확률분포함수(probability distribution function) : . $ f(x)= P(X=x) $ . 이산 확률분포함수의 성질 . 모든 $x$값에 대해 $0 leq f(x) leq 1$ $ sum f(x) =1 $ . . 3.4 확률변수의 기대값과 표준편차 . 확률변수의 기대값(expected value) : 확률변수가 가질 수 있는 값들에 대한 확률분포 상의 중심위치 . $ E(X) = sum xf(x)$ . 평균적으로 한주에 수행하는 경기 수 ($ 0회 times frac{2}{10} + 1회 times frac{5}{10} + 2회 times frac{3}{10} = 1.1회$ ) | . 평균과 다른 점? 기대값은 동일한 실험을 무수히 반복했을 때의 평균을 의미하고 10회 던져서 8번 나왔다고 0.8이라고 하지 않음 실수값을 갖는 확률변수에 대해서, 모평균은 확률변수의 기대값이 된다. . 기대값의 성질 . $ E(X) = mu $ $ E(a) = a $ $ E(aX) = a mu $ $ E(aX pm b) = a mu pm b$ . 확률변수의 분산(variance) . 평균적으로 한주에 수행하는 경기 수의 분산 ($ (0회-1.1회)^2 times frac{2}{10} + (1회-1.1회)^2 times frac{5}{10} + (2회-1.1회)^2 times frac{3}{10} = 0.49 $ ) | . $ Var(X) = sum (x- mu)^2f(x)$ . $ Var(X) = E[ (X - E(X) )^2 ] $ $ Var(X) = E(X^2) - E(X)^2 $ . . 분산의 성질 . $ Var(X) = sigma^2 $ $ Var(a) = 0 $ $ Var(aX) = a^2 sigma^2 $ $ Var(aX pm b) = a^2 sigma^2 $ . 확률변수의 표준편차(standard deviation) . $ sqrt{ Var(X) } = sqrt{ sum (x- mu)^2f(x) } $ . . 3.5 이항분포 . 3.3에서 확률분포란 확률변수가 가지는 값과 그 값을 가질 확률을 정해주는 규칙이라고 정의하였는데, 규칙이 밝혀져 이름이 부여된 것들이 있는데 대표적인 예가 이항분포 . 베르누이 시행 : 단 1회의 실험 지칭 . 베르누이 시행의 특징 . 각 시행은 성공(success, $S$ )과 실패(fail, $F$ )의 두 가지 결과만을 갖는다. | 각 시행에서 성공할 확률은 $P(S)$ , 실패할 확률은 $P(F)$ 로 매 시행마다 동일하다. | 각 시행은 상호 독립으로 각각의 시행이 다른 시행의 결과에 영향을 미치지 않는다. | . 성공 확률이 $p$인 베르누이 시행을 $n$번 시행한 경우 성공 횟수를 나타내는 확률변수 $X$의 확률분포함수는 . $ f(x) = P(X=x) = _{n}C_{x}p^x(1-p)^{n-x} , x=0,1,…,n$ . 이항부포의 기대값과 분산 . 성공 횟수를 나타내는 확률변수 $X$가 $X ~ Bin(n,p)$일 때, $ E(X) = np $ $ E(X) = np(1-p) $ . .",
            "url": "https://nueees.github.io/techblog/statistics/2019/09/01/%EC%9D%B4%EC%82%B0%ED%99%95%EB%A5%A0%EB%B3%80%EC%88%98-%EB%B0%8F-%EB%B6%84%ED%8F%AC.html",
            "relUrl": "/statistics/2019/09/01/%EC%9D%B4%EC%82%B0%ED%99%95%EB%A5%A0%EB%B3%80%EC%88%98-%EB%B0%8F-%EB%B6%84%ED%8F%AC.html",
            "date": " • Sep 1, 2019"
        }
        
    
  
    
        ,"post17": {
            "title": "Internet",
            "content": "📎 Coding Everybody . . 1.1. IP &amp; Domain . IP: 각 장치를 나타내는 IP 주소를 가리키는 말 | Domain: 네트워크상에서 컴퓨터를 식별하는 호스트명 | . IP 기억하기 어렵기 때문에 Domain Name 사용 Domain name -&gt; IP Address로 접속 . DNS (Domain Name Server): 도메인별 IP 정보를 갖고 있는 서버 인터넷에 있는 Name Server에 접속해서 google.com의 IP를 알아낼 수 있음 | . . 1.2. Public &amp; Private IP . public ip: ISP(Internet Service Provider)가 제공하는 인터넷 상에서의 컴퓨터의 주소 | private ip: 어떠한 네트워크(Network) 안에서 사용되는 주소 | . 컴퓨터 여러대 있는 가정의 경우, 공유기(Router)가 설치되어 있으면 IP 접속 실패 Router IP (public IP)에 연결되는 여러대 컴퓨터들(private IP)은 Port forwarding이 필요 . . 1.3. Port . 한 server의 port마다 다른 소프트웨어로 접속됨 | . 예를들어 80번에 있는건 http (web server) port list 확인 . . 1.4. Port Forwarding . 공유기 관리자 192.168.219.1(U+Net) 접속 (ipconfig해서 나오는 무선 LAN 어댑터 기본 게이트웨이) | 고급설정 &gt; NAT 설정 &gt; Port Forwarding | . 80포트로 들어올 때, 80으로 포워딩 되게 내 IPv4 주소 넣고 설정 . . 1.5. DHCP &amp; DDNS . IP 고갈로 인해 IPv4(0.0.0.0 ~ 255.255.255.255) 더이상 사용하기 어려움 현재는 IPv4와 IPv6를 동시에 사용 중 오랫동안 사용하지 않으면 public IP를 회수하고 다시 사용시 새로운 IP로 재할당 . 동적 호스트 구성 프로토콜(Dynamic Host Configuration Protocol, DHCP): 장비에 고정적으로 IP를 부여하지 않고 컴퓨터를 사용할 때 남아 있는 IP 중에서 돌아가면서 부여하는 IP . | 동적 DNS (Dynamic Domain Name System, DDNS): 실시간으로 DNS를 갱신하는 방식으로 도메인과 호스트의 IP를 지속적을 일치화 시켜줌 . | .",
            "url": "https://nueees.github.io/techblog/internet/network/2015/04/15/internet.html",
            "relUrl": "/internet/network/2015/04/15/internet.html",
            "date": " • Apr 15, 2015"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Seeeun Cho . @nueees . CONTACT . Phone: | Email: nueees@gmail.com | Linkedin: https://www.linkedin.com/in/nueees/ | . EXPERTISE . Program languages: SQL, Java, Javascript, Python, R | Frameworks: Spring, MDD (Model-Driven Development) | Version control systems: SVN, Git, frism | Workflow Control: Job-PaSS | DBMSs: Oracle, Mysql | OSs: Linux, Windows | ETL Tools: TDS, TeraStream, BXI, Oracle GoldenGate, DataPump | . EXPERIENCE . Junior data engineer &amp; developer, JT savings bank | Mar 2020 - Sep 2021 | Junior database engineer, Serends IT service | Feb 2019 - Feb 2020 | Java full stack developer, Kyobo information and communication | Sep 2017 - Nov 2018 | . .",
          "url": "https://nueees.github.io/techblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nueees.github.io/techblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}