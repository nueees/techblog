<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Data Lifecycle - Analyze &amp; Visualize</h1><p class="page-description">section3,4</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-10-03T00:00:00-05:00" itemprop="datePublished">
        Oct 3, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/techblog/categories/#gcp">gcp</a>
        &nbsp;
      
        <a class="category-tags-link" href="/techblog/categories/#datastudio">datastudio</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><a href="https://cloud.google.com/architecture/data-lifecycle-cloud-platform#process_and_analyze">Cloud Architecture Center</a></p>

<hr />

<p><img src="/techblog/images/post/data-lifecycle-4.svg" alt="" /></p>

<h1 id="process-and-analyze">Process and analyze</h1>

<h2 id="31-processing-large-scale-data">3.1. Processing large-scale data</h2>
<p>source systems (Google Cloud Storage, Bigtable, Google Cloud SQL) 읽어온 큰 데이터를 처리하고
정규화하고 집계함.
데이터 양이 커서 클러스터로 분산 처리하거나 소프트웨어 툴들의 도움을 받음</p>

<h3 id="dataproc">Dataproc</h3>
<p>cluster에서 실행 (auto scaling)<br />
기존 Hadoop, Hive, Spark 에플리캐이션과 연동<br />
use case: Log processing, Reporting, On-demand Spark clusters, Machine learning</p>

<h3 id="dataflow">Dataflow</h3>
<p>Serverless(cluster X), parallel 처리 (No-Ops)<br />
Spark나 Hadoop과 연동이 아닌 새로운 데이터 pipeline 처리<br />
use case: MapReduce 안쓰는 parallel processing, User analytics, Data science, ETL, Log processing</p>

<h3 id="dataprep">Dataprep</h3>
<p>UI-Driven Data Preparation (No-Ops, 필요시 scaling 가능)
use case: Machine learning, Analytics</p>

<h4 id="connect-dataprep-to-bigquery">connect Dataprep to BigQuery</h4>

<p>1) Create Flow
2) Add dataset (import)
3) Select BigQuery (left pane) &amp; Create dataset
4) Import &amp; Add to Flow</p>

<h4 id="inspect-process-data">inspect, process data</h4>

<p>1) Edit Recipe
dataset의 sample을 Transformer view에서 확인 가능 (visualization)</p>

<h4 id="execute-job-to-load-bigquery">execute job to load BigQuery</h4>

<p>1) click Run in Transformer page<br />
2) click Edit on Create-CSV<br />
3) select BigQuery then create table<br />
4) name output table<br />
5) click Update<br />
6) click Run</p>

<p>job history에서 monitoring 가능</p>

<hr />
<h2 id="32-analyzing-and-querying-data">3.2. Analyzing and querying data</h2>

<h3 id="bigquery">BigQuery</h3>
<p>앞서 store 할 때 뿐만 아니라 분석할 때도 사용<br />
use case: User analysis(adtech, clickstream, game telemetry), Device and operational metrics(IoT), BI</p>

<h3 id="machine-learning">Machine learning</h3>
<p>처리된 결과를 확대시키거나 data-collection 최적화를 제공하기도 하고 결과 예측도 함</p>

<ul>
  <li>음성 인식</li>
  <li>자연어 처리</li>
  <li>번역</li>
  <li>동영상 자동 분석</li>
  <li>AI 플랫폼 (TensorFlow)</li>
</ul>

<hr />
<h1 id="explore-and-visualize">Explore and visualize</h1>

<hr />

<p><a href="https://cloud.google.com/architecture/data-lifecycle-cloud-platform#explore_and_visualize">Cloud Architecture Center</a></p>

<hr />

<h2 id="41-explore-and-visualize">4.1. Explore and visualize</h2>

<h3 id="datalab">Datalab</h3>
<p>interactive한 web 기반 툴<br />
pandas, numpy, scikit-learn 등의 다양한 toolkit 지원</p>

<h3 id="data-science-ecosystem">Data science ecosystem</h3>
<p>Datalab 말고도, web 기반 툴인 Apache Zeppelin 지원
R 사용하면 Rstudio Server나 Microsoft ML Server 지원
Scala나 Java 사용하면 Jupyter 지원</p>

<h2 id="42-visualizing-business-intelligence-results">4.2. Visualizing business intelligence results</h2>

<h3 id="looker">Looker</h3>
<p>BI platform</p>

<h3 id="bi-engine">BI Engine</h3>
<p>analysis service 관리</p>

<h3 id="sheets">Sheets</h3>
<p>Spreadsheet visualization</p>

<h3 id="data-catalog">Data Catalog</h3>
<p>Data discovery and metadata management</p>

<h3 id="data-studio">Data Studio</h3>
<p>Dashboarding and visualization<br />
over 200 connectors ( Google Analytics, BigQuery, Sheets, and external data sources…)</p>

<hr />
<h4 id="practice">Practice</h4>
<p>1) Intro</p>
<ul>
  <li>connect bigquery and data studio</li>
  <li>visualize my data in data studio</li>
</ul>

<p>2) getting set up</p>
<ul>
  <li>accesse public datasets ( <a href="http://g.co/cloud/marketplace-datasets">catalog</a> )</li>
  <li>set up my GCP ( <a href="http://console.cloud.google.com/">my console</a> )</li>
</ul>

<p>3) connecting data studio and bigquery</p>

<p>(1) Open <a href="https://datastudio.google.com/">data studio</a><br />
(2) Start with a Template (Blank template)<br />
(3) Add a data to report Connect to BigQuery (Allow permission to view BigQuery data)<br />
(4) Add table “san_francisco_311” (in public datasets) <br />
(5) Click Manage added data sources under Resources<br />
(6) Edit table fields of “311_service_requests” <br />
(7) “latitude”,”longitude” field from text to Latitude, Longitude in Geo</p>

<p>4) creating visualizations</p>

<ul>
  <li>Click “Add a chart” and select “Treemap”</li>
  <li>Place the “Treemap” chart and change the parameter (“category” field)</li>
</ul>

<p>5) building a dashboard</p>

<ul>
  <li>Click “Add a chart”, select “Google Maps” and change its parameters (Dimension/Tooltip : “neighborhood”, Metric/Bubble size: “record count”)</li>
  <li>Click “Add a chart” and select “Scorecard”</li>
  <li>Select “Add a filter” in the Data panel and create filter (“Street and Sidewalk cleaning” in “category” field)</li>
</ul>

<p>6) creating filters</p>
<ul>
  <li>Click “Filter Control” (set filter dimension to “neighborhood”)</li>
  <li>Click “Arrange” and select “Make page-level”</li>
</ul>

<p>7) test it and share it</p>
<ul>
  <li><a href="https://datastudio.google.com/s/h0mhT-tvKh4">practice_data_studio</a></li>
</ul>

<!-- 
#### Practice02  

1) Intro  
- How a Google Data Studio Community Connector works  
- How to use Google Apps Script to build a Community Connector  
- How to use Community Connectors in Data Studio  

2) Community Connectors  
![image](https://user-images.githubusercontent.com/83441376/140704891-ca0f7c14-9141-4169-8a93-53a05047b9c8.png)  
Fetch data through Web APIs, JDBC APIs, flat files (CSV, JSON, XML), and Apps Script Services.  
ex) after publishing a package on npm, then to tack the download count -> npm package download counts API  

![image](https://user-images.githubusercontent.com/83441376/140705597-1f6c8bad-2e89-4ce9-882e-9ba4c4eaac61.png)  
Work flow:   
- getAuthType()  
- getConfig()  
- getSchema()  
- getData()  
 -->

<hr />


  </div><a class="u-url" href="/techblog/gcp/datastudio/2021/10/03/data-lifecycle-analyze-visualize.html" hidden></a>
</article>